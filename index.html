<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="数据挖掘日常笔记" type="application/atom+xml">






<meta name="description" content="Every failure is leading towards success.">
<meta name="keywords" content="深度学习 机器学习 数据挖掘 推荐 DKT ITS">
<meta property="og:type" content="website">
<meta property="og:title" content="数据挖掘日常笔记">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="数据挖掘日常笔记">
<meta property="og:description" content="Every failure is leading towards success.">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="数据挖掘日常笔记">
<meta name="twitter:description" content="Every failure is leading towards success.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>数据挖掘日常笔记</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband">

    </div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">数据挖掘日常笔记</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Zoe的博客 | Zoe Blog</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>
            
            Schedule
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/29/序列推荐综述/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zoe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据挖掘日常笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/29/序列推荐综述/" itemprop="url">序列推荐综述</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-10-29T15:05:32+08:00">
                2019-10-29
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-10-31T11:27:18+08:00">
                2019-10-31
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐/" itemprop="url" rel="index">
                    <span itemprop="name">推荐</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  11
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="A-Survey-on-Session-based-Recommender-Systems"><a href="#A-Survey-on-Session-based-Recommender-Systems" class="headerlink" title="A Survey on Session-based Recommender Systems"></a>A Survey on Session-based Recommender Systems</h1><p>本文是ACM’18关于session-based recommender systems(SBRS)的综述，文章对SBRS的推荐范式进行了说明，从理论和实践上证明了SBRS的价值；对当前对SBRS进行了系统分类，并从技术及研究的角度对其进行说明；最后总述了SBRS目前的进展及其复杂性和挑战。</p>
<h2 id="推荐系统分类"><a href="#推荐系统分类" class="headerlink" title="推荐系统分类"></a>推荐系统分类</h2><div class="table-container">
<table>
<thead>
<tr>
<th>推荐系统</th>
<th>输入</th>
<th>核心假设</th>
<th>工作机制</th>
<th>优势</th>
<th>劣势  </th>
</tr>
</thead>
<tbody>
<tr>
<td>基于内容</td>
<td>user和item content</td>
<td>根据用户的 喜好做推荐</td>
<td>根据item content建模</td>
<td>简单直接 可以解决用户的冷启动</td>
<td>用户兴趣会变化，跟现实场景会有出入</td>
</tr>
<tr>
<td>协同过滤（CF）</td>
<td>User-item交互数据</td>
<td>根据用户喜好</td>
<td>User-item交互数据建模</td>
<td>有效且相对简单</td>
<td>容易陷入数据稀疏带来的问题， 冷启动问题</td>
</tr>
<tr>
<td>上下文可感知的RS</td>
<td>User， item， 上下文，user-item交互数据</td>
<td>用户在不同上下文环境下有不同的喜好</td>
<td>对User-item 上下文 交互信息进行建模</td>
<td>User-item交互数据建模</td>
<td>可用数据及数据稀疏的问题</td>
</tr>
<tr>
<td>SBRS</td>
<td>Session的数据</td>
<td>用户的喜好随着session的变化而变化</td>
<td>推荐出现在相似的session环境中的items</td>
<td>考虑到用户喜好的变化，更好的符合现实场景</td>
<td>会忽略用户长期的更general的喜好</td>
</tr>
</tbody>
</table>
</div>
<h2 id="SBRS相关定义及符号表示"><a href="#SBRS相关定义及符号表示" class="headerlink" title="SBRS相关定义及符号表示"></a>SBRS相关定义及符号表示</h2><p>定义如下符号表示： </p>
<p>用户：u</p>
<p>用户集合： $U=\left\{u_{1}, u_{2}, \ldots, u_{|U|}\right\}$</p>
<p>物品： i</p>
<p>物品集合：$I=\left\{i_{1}, i_{2}, \ldots, i_{|I|}\right\}$</p>
<p>session： $s=\left\{i_{1}, i_{2}, \ldots, i_{|s|}\right\}$</p>
<p>session集合： $S=\left\{s_{1}, s_{2}, \dots, s_{|S|}\right\}$</p>
<p>待预测/推荐物品为： t</p>
<p>Intra-session context： $C^{I a}$</p>
<p>Inter-seesion context： $C^{I e}$</p>
<p>session的定义： 一段时间内用户消费/收集的一系列事件内的item集合</p>
<p>SBRS定义： SBRS的任务是给定session的部分信息对未知/未来的信息进行预测。</p>
<p>Intra-session context定义: $s_{n}$为当前待推荐session，则$C^{I a}=\left\{i | i \in s_{n}, i \neq i_{t}\right\}$</p>
<p>Inter-session context定义： $s_{n}$为当前待推荐session，$C^{I e}=\left\{s_{n-1}, s_{n-2}, \dots, s_{\left|c^{I e}\right|}\right\}$</p>
<p>session-based recommendation task定义： 给定一个session语境C，session-based recommendation是学习一个从C到t的函数f使得$t: t \Leftarrow f(C)$。在SBRS中，session context是首要的信息，其他如用户或item信息也可以添加到模型中。</p>
<p>Next-items recommendation： 给定当前session $s_{n}$和intra-session context$C^{Ia}$预测$i_{t}$</p>
<p>Next-sessopm(next-basket) recommendations: 给定当前session$s_{n}$和inter-session context $C^{Ie}$预测下一个session的items。</p>
<h2 id="SBRS的意义，复杂性和挑战"><a href="#SBRS的意义，复杂性和挑战" class="headerlink" title="SBRS的意义，复杂性和挑战"></a>SBRS的意义，复杂性和挑战</h2><ul>
<li>意义和价值： SBRS在学术和商业上都具有重要意义。</li>
<li><p>复杂性：</p>
<ul>
<li><p>数据的复杂性</p>
<p>如下图所示，数据可以分为如下五个等级，SBRS需要的是中间核心的三个（item feature level， item level 和session level）。<br><img src="/2019/10/29/序列推荐综述/1.jpg" alt="1"></p>
</li>
</ul>
</li>
<li><p>挑战： 上图右侧描述了每层的一些挑战，按照层级可以分为 Inner-session，Inter-session， Outer-session的挑战。也可以按照类别分为异质性，共生性，复杂性和相互作用四大类。</p>
</li>
</ul>
<h2 id="Overview-of-SBRS"><a href="#Overview-of-SBRS" class="headerlink" title="Overview of SBRS"></a>Overview of SBRS</h2><p>SBRS的发展可以分为两阶段： 1990s到2010s的model-free阶段，主要依赖pattern或规则去做。第二阶段是从2010s到现在的model-based阶段，主要采用统计和机器学习算法来做，包括时序相关的马尔可夫链，rnn等。</p>
<h2 id="SBRS的分类和总结"><a href="#SBRS的分类和总结" class="headerlink" title="SBRS的分类和总结"></a>SBRS的分类和总结</h2><h3 id="从研究问题的角度做分类"><a href="#从研究问题的角度做分类" class="headerlink" title="从研究问题的角度做分类"></a>从研究问题的角度做分类</h3><ul>
<li><p>按照推荐什么做分类：</p>
<ul>
<li>Next-item: 有明显session划分的预测下一个<ul>
<li><a href="http://ceur-ws.org/Vol-1922/paper11.pdf" target="_blank" rel="noopener">Incorporating dwell time in session-based recommendations with recurrent Neural networks </a>  2017</li>
<li><a href="https://arxiv.org/pdf/1706.04026.pdf" target="_blank" rel="noopener"> Recurrent Latent Variable Networks for Session-Based<br>Recommendation </a> 2017</li>
<li><a href="https://pdfs.semanticscholar.org/9f97/6eea4bd54141dfaf13d2f0fddd4fff48e73b.pdf" target="_blank" rel="noopener">A Variational Recurrent Neural Network for Session-Based<br>Recommendations using Bayesian Personalized Ranking</a>2017</li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.3821&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Web path recommendations based on page ranking and<br>markov models</a> 2005</li>
<li><a href="http://ceit.aut.ac.ir/~meybodi/paper/paper/Forsati-2009-Conference%20on%20Electronic%20Computer%20Conference%20(ICECT%202009),%20Macao,WeightedRule.pdf" target="_blank" rel="noopener">Web page personalization based on weighted association rules</a> 2009</li>
<li><a href="https://www.researchgate.net/publication/314506392_Session-Based_Recommendations_Using_Item_Embedding" target="_blank" rel="noopener">Session-based recommendations using item embedding</a> 2017</li>
<li><a href="https://arxiv.org/pdf/1706.03847.pdf" target="_blank" rel="noopener">Recurrent Neural Networks with Top-k Gains for Session-based Recommendations</a> 2017</li>
<li><a href="https://arxiv.org/pdf/1511.06939.pdf" target="_blank" rel="noopener">Session-based recommendations with recurrent<br>neural networks</a> 2015</li>
<li><a href="https://alexiskz.files.wordpress.com/2016/06/feature-rnn-paper1.pdf" target="_blank" rel="noopener"> Parallel recurrent neural network architectures<br>for feature-rich session-based recommendations</a> 2016</li>
<li><a href="https://www.ijcai.org/proceedings/2017/0258.pdf" target="_blank" rel="noopener">Diversifying personalized recommendation<br>with user-session context</a> 2017</li>
<li><a href="https://dl.acm.org/citation.cfm?id=3109872" target="_blank" rel="noopener">When recurrent neural networks meet the neighborhood for session-based recommendation</a> 2017</li>
<li><a href="https://www.researchgate.net/publication/319582690_Session-based_item_recommendation_in_e-commerce_on_short-term_intents_reminders_trends_and_discounts" target="_blank" rel="noopener"> Session-based item recommendation in e-commerce: on short-term intents,reminders, trends and discounts</a> 2017</li>
<li><a href="http://www.cs.toronto.edu/~lcharlin/papers/cofactorization.pdf" target="_blank" rel="noopener">Factorization meets the item embedding: Regularizing matrix<br>factorization with item co-occurrence</a> 2016</li>
<li><a href="https://arxiv.org/pdf/1709.01532.pdf" target="_blank" rel="noopener">Interacting Attention-gated Recurrent Networks<br>for Recommendation</a>2017</li>
<li><a href="https://arxiv.org/pdf/1706.04148.pdf" target="_blank" rel="noopener">Personalizing Session-based Recommendations<br>with Hierarchical Recurrent Neural Networks</a> 2017</li>
<li><a href="https://arxiv.org/pdf/1706.07506.pdf" target="_blank" rel="noopener">Inter-Session Modeling for Session-Based Recommendation</a> 2017</li>
<li><a href="https://arxiv.org/pdf/1606.08117.pdf" target="_blank" rel="noopener">Improved recurrent neural networks for session-based recommendations</a>2016</li>
<li><a href="http://ecmlpkdd2017.ijs.si/papers/paperID293.pdf" target="_blank" rel="noopener">Perceiving the Next Choice with Comprehensive Transaction Embeddings for Online Recommendation</a> 2017</li>
<li>Attention-based Transactional Context<br>Embedding for Next-Item Recommendation 2018</li>
<li><a href="https://www.ntu.edu.sg/home/XLLI/publication/DASFAA11_Recommendation.pdf" target="_blank" rel="noopener">Effective next-items recommendation via personalized sequential pattern mining</a> 2012</li>
<li><a href="https://www.ijcai.org/proceedings/2018/0546.pdf" target="_blank" rel="noopener">Sequential<br>Recommender System based on Hierarchical Attention Networks</a> 2018</li>
</ul>
</li>
<li>Next-basket： 有明显session划分的预测下一个session<ul>
<li><a href="http://ramb.ethz.ch/CDstore/www2010/www/p811.pdf" target="_blank" rel="noopener">Factorizing personalized markov chains for next-basket<br>recommendation</a> 2010</li>
<li><a href="http://ceur-ws.org/Vol-1441/recsys2015_poster15.pdf" target="_blank" rel="noopener">Next Basket Recommendation with Neural<br>Networks</a> 2015</li>
<li><a href="http://www.bigdatalab.ac.cn/~junxu/publications/SIGIR2015_NextBasketRec.pdf" target="_blank" rel="noopener"> Learning hierarchical representation<br>model for nextbasket recommendation</a> 2015</li>
<li><a href="http://cseweb.ucsd.edu/classes/fa17/cse291-b/reading/A%20Dynamic%20Recurrent%20Model%20for%20Next%20Basket%20Recommendation.pdf" target="_blank" rel="noopener">A dynamic recurrent model for next basket recommendation</a> 2016</li>
</ul>
</li>
<li>Next-event/action： 无明显session划分<ul>
<li><a href="https://www.ijcai.org/proceedings/2018/0458.pdf" target="_blank" rel="noopener"> Content-Aware Hierarchical Point-of-Interest<br>Embedding Model for Successive POI Recommendation</a> 2018</li>
<li><a href="https://pdfs.semanticscholar.org/01a0/438352146dea1129121a94fe428d97971547.pdf" target="_blank" rel="noopener">Where You Like to Go Next: Successive Point-of-Interest Recommendation</a> 2013</li>
<li><a href="http://mac.citi.sinica.edu.tw/~yang/pub/chou16recsys.pdf" target="_blank" rel="noopener">Addressing cold start for next-song recommendation</a> 2016</li>
<li><a href="https://pdfs.semanticscholar.org/d0ca/f22825647365a86ae4bf8749cfbe48789a8c.pdf" target="_blank" rel="noopener">Personalized Ranking Metric Embedding<br>for Next New POI Recommendation</a> 2015</li>
<li><a href="http://www2013.w3c.br/companion/p231.pdf" target="_blank" rel="noopener">Collaborative filtering meets next check-in location prediction</a> 2013</li>
<li><a href="https://dl.acm.org/citation.cfm?id=3210159" target="_blank" rel="noopener"> K-plet Recurrent Neural Networks for Sequential Recommendation</a> 2018</li>
<li><a href="http://staff.ustc.edu.cn/~cheneh/paper_pdf/2013/sys145-wu.pdf" target="_blank" rel="noopener">Personalized next-song recommendation in<br>online karaokes</a> 2013</li>
</ul>
</li>
</ul>
</li>
<li><p>按照如何推荐做分类：</p>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>进展</th>
<th>缺点     </th>
</tr>
</thead>
<tbody>
<tr>
<td>Item-level dependency modeling</td>
<td>patten-based, 马尔可夫链模型， RNN， attention</td>
<td>item 不平衡（如热门商品），长尾商品</td>
</tr>
<tr>
<td>Session-level dependency modeling</td>
<td>因子分解机， RNN等</td>
<td>长期依赖，上下文感知，inter-seesion依赖</td>
</tr>
<tr>
<td>Feature-level dependency modeling</td>
<td>因子分解机， RNN， CNN</td>
<td>特征的异构和依赖</td>
</tr>
<tr>
<td>Feature value-level dependency modeling</td>
<td>目前没有进展</td>
<td>特征值的异构和依赖，item-feature-value的交互</td>
</tr>
<tr>
<td>Domain-level dependency modeling</td>
<td>目前没有进展</td>
<td>Domain间的互补和交互</td>
</tr>
</tbody>
</table>
</div>
<h3 id="从技术的角度进行分类"><a href="#从技术的角度进行分类" class="headerlink" title="从技术的角度进行分类"></a>从技术的角度进行分类</h3><h4 id="model-free方法"><a href="#model-free方法" class="headerlink" title="model-free方法"></a>model-free方法</h4><p>model-free的方法主要包括：</p>
<ul>
<li>基于pattern/规则</li>
<li>基于序列pattern</li>
</ul>
<h3 id="model-based-方法"><a href="#model-based-方法" class="headerlink" title="model-based 方法"></a>model-based 方法</h3><p>model-based 方法包括：</p>
<ul>
<li>基于马尔可夫链的推荐，基于转移概率考虑一阶依赖。</li>
<li>因子分解机，首先将共现矩阵或item-item转移矩阵进行分解，得到item的隐变量，基于隐变量做推荐。</li>
<li>基于神经网络的方法，如考虑序列的RNN等。</li>
</ul>
<h2 id="model-free方法介绍"><a href="#model-free方法介绍" class="headerlink" title="model-free方法介绍"></a>model-free方法介绍</h2><p>基于pattern/规则的推荐系统主要分三阶段：1.最高频的pattern挖掘，session匹配和item推荐。</p>
<p>常见的基于高频pattern的挖掘有Apriori，FR-Tree及相关变形。<br>基于session pattern的方法和高频pattern 的挖掘相似，但是有一下两个不同点：1.主要考虑inter-seesion的信息而不是intra-session的信息。2.是对序列信息进行挖掘的。</p>
<h2 id="model-based-方法介绍"><a href="#model-based-方法介绍" class="headerlink" title="model-based 方法介绍"></a>model-based 方法介绍</h2><h3 id="基于马尔可夫链的推荐方法"><a href="#基于马尔可夫链的推荐方法" class="headerlink" title="基于马尔可夫链的推荐方法"></a>基于马尔可夫链的推荐方法</h3><p>马尔可夫链模型可以描述为$\left\{S T, P_{t}, P_{0}\right\}$，其中ST为状态空间，$P_{t}$为状态转移矩阵，$P_{0}$为初始状态概率，一阶状态转移概率为：</p>
<p>$P_{t}(j, k)=P\left(i_{j} \rightarrow i_{k}\right)=\frac{f r e q\left(i_{j} \rightarrow i_{k}\right)}{\sum_{i_{t} \in I} f r e q\left(i_{j} \rightarrow i_{t}\right)}$</p>
<p>由上述公式我们可以得到$\{i_{1}\rightarrow i_{2} \rightarrow i_{3}\}$的概率为：<br>$P\left(i_{1} \rightarrow i_{2} \rightarrow i_{3}\right)=P\left(i_{1}\right) <em> P\left(i_{2} | i_{1}\right) </em> P\left(i_{3} | i_{2}\right)$</p>
<p>通过上述公式我们可以计算给定session 部分序列时某一item的概率从而做推荐。</p>
<p>除了上述基本的模型外，有其他一些变形，包括结合<a href="https://www.researchgate.net/publication/4309784_Efficient_Hybrid_Web_Recommendations_Based_on_Markov_Clickstream_Models_and_Implicit_Search" target="_blank" rel="noopener">一阶二阶马尔可夫的模型</a>，有结合<a href="https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=4357&amp;context=sis_research" target="_blank" rel="noopener">隐马尔可夫的概率模型</a>，还有结合因子分解做一些工作。</p>
<h3 id="基于因子分解机的推荐方法"><a href="#基于因子分解机的推荐方法" class="headerlink" title="基于因子分解机的推荐方法"></a>基于因子分解机的推荐方法</h3><p>由上述可知，根据观测数据可以计算转移概率，从而形成转移概率矩阵$A^{u}$，需要注意的是上述转移概率矩阵是某一个用户的，因此所有用户的概率转移矩阵为$\mathfrak{A}^{|U| \times|I| \times|I|}$，最基本的因子分解模型是基于Tucker降维：</p>
<p>$\hat{\mathscr{H}}=C \times V_{U} \times V_{I_{j}} \times V_{I_{k}}$</p>
<p>其中C为核张量，$V_{U}$为用户特征矩阵，$V_{I_{j}}$，$V_{I_{k}}$分别为当前item的特征矩阵和下一个item的特征矩阵。</p>
<h3 id="基于神经网络的推荐方法"><a href="#基于神经网络的推荐方法" class="headerlink" title="基于神经网络的推荐方法"></a>基于神经网络的推荐方法</h3><p>基于神经网络的推荐方法主要分两大类：基于embedding的浅层的神经网络推荐模型和多层的深度神经网络推荐模型。</p>
<h4 id="浅层神经网络"><a href="#浅层神经网络" class="headerlink" title="浅层神经网络"></a>浅层神经网络</h4><p>主要是受到word2vec的启发，这种方法将item序列理解为句子，item为词，使用同word2vec的方法可以学习得到高维空间中item的表示，从而item embedding的距离可以表示为他们的关系，基于此做推荐。其他的变形包括加入item feature或其他相关feature做embedding，或加入attention机制，都是自然语言中常见的几种方法。</p>
<h4 id="深层神经网络"><a href="#深层神经网络" class="headerlink" title="深层神经网络"></a>深层神经网络</h4><p>深层神经网络主要从2016年开始，主要包括基于RNN的,基于DNN的和基于CNN的。</p>
<ul>
<li><p>基于RNN： 更好得捕捉序列关系</p>
<p>  最基础的是GRU4REC模型，输入item序列，输出item的概率分布（同最基础的语言模型）。为提升GRU4REC的效果，<a href="https://arxiv.org/pdf/1606.08117.pdf" target="_blank" rel="noopener">Tan</a>提出数据增广和embedding dropout两种策略训练GRU4REC模型，同时提出一个generalised distillation framework；<a href="https://arxiv.org/pdf/1706.04148.pdf" target="_blank" rel="noopener">Quadrana</a>提出层次RNN结构来捕捉跨session 的信息;<a href="https://cseweb.ucsd.edu/classes/fa17/cse291-b/reading/p152-donkers.pdf" target="_blank" rel="noopener">Tim Donkers</a>提出结合用户属性的user-based GRU来产生用户个性化推荐。</p>
<p>  除了基于GRU4REC的推荐模型，还有基于RNN的一些变形模型，如<a href="http://cseweb.ucsd.edu/classes/fa17/cse291-b/reading/A%20Dynamic%20Recurrent%20Model%20for%20Next%20Basket%20Recommendation.pdf" target="_blank" rel="noopener">Dynamic REcurrent bAsket Model (DREAM)</a>，通过每个时刻的隐状态学习用户变化的表示。</p>
<p>  其他的一些进展包括：1.RNN结合变分推断解决稀疏数据的不确定性和降低模型规模[2,3]；2.结合更丰富的信息如上下文信息，位置，item feature等来提升模型的效果[4,5,6];3.加入attention机制<a href="https://arxiv.org/pdf/1706.03847.pdf" target="_blank" rel="noopener">7</a>;4.结合传统的FM或KNN等模型</p>
</li>
<li><p>基于DNN：常用于当一个session中无序列关系时，如一个购物车中的物品。</p>
</li>
<li><p>基于CNN：同样适用于无严格序列关系的session数据，并且具有更强的局部特征的捕捉能力，可以跨区域捕捉RNN常常捕捉不到的联合依赖关系。</p>
</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ol>
<li><p><a href="https://arxiv.org/pdf/1902.04864.pdf" target="_blank" rel="noopener">A Survey on Session-based Recommender Systems</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1706.04026.pdf" target="_blank" rel="noopener">Recurrent Latent Variable Networks for Session-Based<br>Recommendation</a></p>
</li>
<li><a href="https://pdfs.semanticscholar.org/9f97/6eea4bd54141dfaf13d2f0fddd4fff48e73b.pdf" target="_blank" rel="noopener">A Variational Recurrent Neural Network for Session-Based<br>Recommendations using Bayesian Personalized Ranking</a></li>
<li><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/46488.pdf" target="_blank" rel="noopener">Latent Cross: Making Use of Context in<br>Recurrent Recommender Systems</a></li>
<li><a href="https://alexiskz.files.wordpress.com/2016/06/feature-rnn-paper1.pdf" target="_blank" rel="noopener">Parallel Recurrent Neural Network Architectures for Feature-rich Session-based Recommendations</a></li>
<li><a href="http://ceur-ws.org/Vol-1922/paper11.pdf" target="_blank" rel="noopener">Incorporating Dwell Time in Session-Based Recommendations with Recurrent Neural Networks</a></li>
<li><a href="https://arxiv.org/pdf/1709.01532.pdf" target="_blank" rel="noopener">Interacting Attention-gated Recurrent Networks for Recommendation</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/25/序列推荐/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zoe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据挖掘日常笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/25/序列推荐/" itemprop="url">序列推荐</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-10-25T10:35:27+08:00">
                2019-10-25
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-10-29T10:17:55+08:00">
                2019-10-29
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐/" itemprop="url" rel="index">
                    <span itemprop="name">推荐</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  11
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Session-Based-Recommendations-With-Recurrent-Neural-Networks"><a href="#Session-Based-Recommendations-With-Recurrent-Neural-Networks" class="headerlink" title="Session-Based Recommendations With Recurrent Neural Networks"></a>Session-Based Recommendations With Recurrent Neural Networks</h1><p>这篇是2016 ICLR的一篇文章，考虑到现实生活中更多的推荐场景是基于短期session而不是长期的用户历史，因此如MF等方法就不是很准确，因此本文提出将RNN应用于基于session的推荐系统。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p><img src="/2019/10/25/序列推荐/1.jpg" alt="1"></p>
<p>输入对应session内的点击序列，采用one-hot编码，输出为预测的item被点击的概率。为适应推荐任务，作者做了以下几个优化：</p>
<h3 id="session-parallel-mini-batches"><a href="#session-parallel-mini-batches" class="headerlink" title="session-parallel mini-batches"></a>session-parallel mini-batches</h3><p>由于用户一个session内的行为差别很大，比如有的时候只有两个动作，有的时候会有上百个，而我们希望捕捉的是session内的行为模式，因此不希望通过截断来提高训练效率，因此作者提出来session-parrallel mini-batches，即拼接不同的session减少无效计算，具体如下图所示：<br><img src="/2019/10/25/序列推荐/2.jpg" alt="2"><br>如上图mini-batch3所示，当session2结束后继续接入session4而不是通过padding实现，避免浪费计算。当接入新的session时，需要将对应的隐状态重置。</p>
<h3 id="smapling-on-the-output"><a href="#smapling-on-the-output" class="headerlink" title="smapling on the output"></a>smapling on the output</h3><p>由于item数量常常是巨大的，对每一个item在每一个step计算一个得分无疑是巨大的计算量，在实际应用中也会变得不可用。因此作者提出对output进行采样，只对采样得到的正样本和一些负样本计算得分。</p>
<p>对于采样方法，作者采用的是同一个mini-batch中其他sequence的下一个点击的item作为负样本。</p>
<h3 id="ranking-loss"><a href="#ranking-loss" class="headerlink" title="ranking loss"></a>ranking loss</h3><p>排序可以分为pointwise,pairwise和listwise三种，pointwise ranking的损失函数是对单点预测结果和实际之间对差异。pairwise ranking的损失函数是对pair的预测效果和真实之间的差异。listwise可以通过pairwise实现。本文作者尝试了pointwise和pairwise的损失，发现基于pointwise的loss训练出的模型不稳定，因此采用了pairwise的损失。具体包含以下两种：</p>
<ul>
<li><p>BPR(Bayesian Personalized Ranking) 一种矩阵分解的方法</p>
<p>$L_{s} = -\frac{1}{N_{S}} \cdot \sum_{j=1}^{N_{S}} \log \left(\sigma\left(\hat{r}_{s, i}-\hat{r}_{s, j}\right)\right)$</p>
<p>其中$N_{S}$为采样大小，$\hat{r}_{s, k}$为给定session下item k的得分。</p>
</li>
<li><p>TOP1 一种正则估计</p>
<p>$L_{s}=\frac{1}{N_{S}} \cdot \sum_{j=1}^{N_{S}} \sigma\left(\hat{r}_{s, j}-\hat{r}_{s, i}\right)+\sigma\left(\hat{r}_{s, j}^{2}\right)$</p>
</li>
</ul>
<h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p>文章主要贡献就是将RNN应用于推荐领域（虽然现在看没有什么新意），更具有参考意义的是作者提到的训练上优化的点。</p>
<h1 id="Parallel-Recurrent-Neural-Network-Architectures-for-Feature-rich-Session-based-Recommendations"><a href="#Parallel-Recurrent-Neural-Network-Architectures-for-Feature-rich-Session-based-Recommendations" class="headerlink" title="Parallel Recurrent Neural Network Architectures for Feature-rich Session-based Recommendations"></a>Parallel Recurrent Neural Network Architectures for Feature-rich Session-based Recommendations</h1><p>这是发表于RecSys‘16的一篇文章，主要提出结合item信息的基于session的RNN架构。</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p><img src="/2019/10/25/序列推荐/3.jpg" alt="3"></p>
<p>文章所提出的模型架构如上图所示，主要包括以下几个架构：</p>
<ul>
<li>Baseline architectures：<ul>
<li>ID only是指只用session 中click item的ID经one-hot作为输入的RNN模型（就是第一篇paper中的模型）。</li>
<li>feature only是指只用item的image feature作为输入的模型（用item文本信息也是一样的道理）。</li>
<li>Concatenated input是将ID 和image feature concat作为输入送入模型，这也是大家都能想到的结合item feature的方法了。</li>
</ul>
</li>
<li>p-RNN architectures:<ul>
<li>Parallel 是将ID和image feature分别送入RNN，隐藏层concat之后做预测。</li>
<li>Parallel Shared-W 与parallel区别的是共享一个用于计算输出的权重矩阵，整个架构类似来自上下文感知因子分解的pariwise的模型。</li>
<li>Parallel interaction model 这个架构中 image feature的隐状态会和ID 的隐状态做逐元素相乘后再计算推荐结果（类似上下文感知偏好建模），其中计算输出的权重矩阵不共享。</li>
</ul>
</li>
</ul>
<p>模型用到的损失函数是上文提到的TOP1损失。</p>
<h3 id="p-RNNs训练"><a href="#p-RNNs训练" class="headerlink" title="p-RNNs训练"></a>p-RNNs训练</h3><p>对于p-RNNs的训练，作者提出了以下几个策略：</p>
<ul>
<li>Simultaneous: 所有的子图同时训练</li>
<li>Alternating： 交替训练，如第一个epoch训练ID的子图，第二个epoch训练feature的子图，交替往复直到训练结束。</li>
<li>Residual： 子图一个接一个的训练，当ID子图训练完成后，feature的子图基于残差继续训练。</li>
<li>Inrerleaving： 每个mini-batch交替训练。</li>
</ul>
<p>论文实验结果表示Parallel并行更新item ID和feature的模型效果最好，Parallel Shared-W和Parallel interaction model效果没有很好可能是重复的序列信息加重了模型训练的负担。</p>
<h2 id="总结：-1"><a href="#总结：-1" class="headerlink" title="总结："></a>总结：</h2><p>本文主要是提出了几种结合item feature的架构，虽然最终实验结果表明Parallel具有最好的结果，但是面对实际业务其他的架构及训练策略还是具有一定借鉴意义的。</p>
<h1 id="Incorporating-Dwell-Time-in-Session-Based-Recommendations-with-Recurrent-Neural-Networks"><a href="#Incorporating-Dwell-Time-in-Session-Based-Recommendations-with-Recurrent-Neural-Networks" class="headerlink" title="Incorporating Dwell Time in Session-Based Recommendations with Recurrent Neural Networks"></a>Incorporating Dwell Time in Session-Based Recommendations with Recurrent Neural Networks</h1><p>本文是RecSys‘17的一篇文章，主要提出将item停留时长考虑进去基于session 的RNN建模。</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>模型架构与<a href="https://arxiv.org/pdf/1511.06939.pdf" target="_blank" rel="noopener">第一篇paper</a>中的架构完全一样，只是在session的构建上，如下图所示：<br><img src="/2019/10/25/序列推荐/4.jpg" alt="4"></p>
<p>作者认为，用户停留的时间越长表明越感兴趣，将用户在每个item上的停留时间按照单位时间t进行划分，得到如上图中的session。考虑到用户停留时长的session划分能够起到item boosting的效果。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇文章短小而精悍，相比于第一篇paper只是考虑到用户时长将session进行划分的不同就可以得到非常大的提升。看到题目标题时，笔者也只是在考虑是将用户停留时长做feature一起送入模型，没想到是采用这样的方式，只是很奇妙的。</p>
<h1 id="Personalizing-Session-based-Recommendations-with-Hierarchical-Recurrent-Neural-Networks"><a href="#Personalizing-Session-based-Recommendations-with-Hierarchical-Recurrent-Neural-Networks" class="headerlink" title="Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks"></a>Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks</h1><p>这也是RecSys‘17的一篇文章，主要提出层级RNN结构能够捕获session内信息和跨session的信息（如用户兴趣的变迁等）从而做用户的个性化推荐。</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p><img src="/2019/10/25/序列推荐/5.jpg" alt="5"></p>
<p>上图为本文提出的HRNN架构图，红框对应session-level GRU，蓝框对应user-level GRU。 session-level GRU输入为session内item ID的one-hot编码，输出为预测的item的score。训练时损失可以采用cross-entrop，BRP或TOP1.</p>
<p>对于一个用户多session时，当一个session结束时，用session-level GRU的输出来计算当前user-level GRU的表示：<br>$c_{m}=G R U_{u s r}\left(s_{m}, c_{m-1}\right), m=1, \ldots, M_{u}$，</p>
<p>user-levelGRU的表示来初始化下一个session的输入：$s_{m+1,0}=\tanh \left(W_{i n i t} c_{m}+b_{i n i t}\right)$</p>
<p>随着迭代，$s_{m+1, n}=G R U_{s e s}\left(i_{m+1, n}, s_{m+1, n-1}\left[, c_{m}\right]\right), n=1, \ldots, N_{m+1}-1      \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ …（1）$</p>
<p>训练是端到端进行的，user-level GRU只有在session结束时才更新。</p>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>本文提供了一种可以综合跨session信息的策略，从而可以捕捉到诸如用户兴趣变迁等信息。</p>
<h1 id="When-Recurrent-Neural-Networks-meet-the-Neighborhood-for-Session-Based-Recommendation"><a href="#When-Recurrent-Neural-Networks-meet-the-Neighborhood-for-Session-Based-Recommendation" class="headerlink" title="When Recurrent Neural Networks meet the Neighborhood for Session-Based Recommendation"></a>When Recurrent Neural Networks meet the Neighborhood for Session-Based Recommendation</h1><p>这也是RecSys‘17的一篇文章，本文主要在基于session-bases rnn model的基础上，结合了KNN，实验结果显示对推荐结果有了进一步对提升。</p>
<h2 id="模型-4"><a href="#模型-4" class="headerlink" title="模型"></a>模型</h2><p>如果一个item在和当前item相似的session中出现过，则这个item出现的可能性更大，基于这种考虑，作者提出了基于session-based KNN。</p>
<h3 id="GRU4REC"><a href="#GRU4REC" class="headerlink" title="GRU4REC"></a>GRU4REC</h3><p>与论文1中提出的session-based RNN一致</p>
<h3 id="Session-based-KNN"><a href="#Session-based-KNN" class="headerlink" title="Session-based KNN"></a>Session-based KNN</h3><p> 根据当前session找到最相近的K个历史session，item i在当前session出现的概率为：</p>
<p>$score_{KNN} ( i , s )=\Sigma_{n \in N_{s}} \operatorname{sim}(s, n) \times 1_{n}(i)$</p>
<p>其中sim(s,n)可以是各种衡量相似度的公式（作者实验得cosine取得最好的结果），$1_{n}(i)=1$指当session n中包含item i为1，否则为0.</p>
<h3 id="Hybird-Approach"><a href="#Hybird-Approach" class="headerlink" title="Hybird Approach"></a>Hybird Approach</h3><p>两个方法综合的方式有switching，cascading和weighted hybirds。作者实验结果表明weighted hybirds方式可以取得最好的结果。</p>
<h2 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h2><p>本文提出了一种基于session-based KNN模型，KNN更多的是关注近期数据表现，RNN相对可以捕获更长的序列，混合模型对结果还是会有提升。</p>
<h1 id="Improved-Recurrent-Neural-Networks-for-Session-based-Recommendations"><a href="#Improved-Recurrent-Neural-Networks-for-Session-based-Recommendations" class="headerlink" title="Improved Recurrent Neural Networks for Session-based Recommendations"></a>Improved Recurrent Neural Networks for Session-based Recommendations</h1><p>DLRS’16的一篇文章，在GRU4REC（paper1 介绍的session-based RNN）基础上提出的两条提升模型效果的方法，并且提出了一个generalised distillation framework来替代原有模型。</p>
<h2 id="提升模型效果的方法"><a href="#提升模型效果的方法" class="headerlink" title="提升模型效果的方法"></a>提升模型效果的方法</h2><p>GRU4REC是对$\mathbf{x}=\left[x_{1}, x_{2}, \ldots, x_{r-1}, x_{r}\right]$这样的session序列做预测，本质是一个分类模型。由于session内数据变化很大，而我们的任务是作出对任意长度都适用的模型。</p>
<h3 id="Data-Augument"><a href="#Data-Augument" class="headerlink" title="Data Augument"></a>Data Augument</h3><p>给定一个session的输入序列$\mathbf{x}$，可以产生出多条训练数据如$\left(\left[x_{1}\right], V\left(x_{2}\right)\right),\left(\left[x_{1}, x_{2}\right], V\left(x_{3}\right)\right), \ldots\left(\left[x_{1}, x_{2}, \ldots, x_{n-1}\right], V\left(x_{n}\right)\right)$，同时用户能存在误点击的操作，因此可以引入dropout的方式来做泛化。总体结果如下图所示：<br><img src="/2019/10/25/序列推荐/6.jpg" alt="6"></p>
<h3 id="Adapting-to-temporal-changes"><a href="#Adapting-to-temporal-changes" class="headerlink" title="Adapting to temporal changes"></a>Adapting to temporal changes</h3><p>机器学习算法的一个基本假设是数据独立同分布的，对于推荐的数据，显然并不是严格成立的：当item被显示时用户才有可能点击，并且用户的行为是随时时间变化的。推荐的任务是根据用户当前的行为预测下一个点击的item，因此应该更关注的是当前的行为序列而不是更早之前的行为。而训练通常会采用全历史行为记录去做模型，因此可能引入偏差。</p>
<p>为缓解上述问题，可以简单的设置一个空间上的门限，大概门限值的记录就可以舍弃。另一种是采用预训练的方法，首先用全量数据做训练，之后再用近期的数据做fine-tune。</p>
<h3 id="Use-of-privileged-information"><a href="#Use-of-privileged-information" class="headerlink" title="Use of privileged information"></a>Use of privileged information</h3><p>这部分对应作者提出的generalised distillation framework。给定的序列$x_{1},x_{2}\ldots x_{r-1}$预测$x_{r}$，作者称$x_{r+1},\ldots x_{n}$为privileged information，其对应的privileged sequence 为$x^{<em>}=\left[x_{n}, x_{n-1} \ldots x_{r+2}\right]$。其中n为原始序列的总长度。首先可以以privileged sequence训练teacher model，然后再tune student model，其loss function为：<br>$(1-\lambda) </em> L\left(M(\mathbf{x}), V\left(x_{n}\right)\right)+\lambda <em> L\left(M(\mathbf{x}), M^{</em>}\left(\mathbf{x}^{<em>}\right)\right)$。其中$\lambda \in[0,1]，$M对应student model，$M^{</em>}$为teacher model。</p>
<h3 id="Output-embeddings-for-faster-predictions"><a href="#Output-embeddings-for-faster-predictions" class="headerlink" title="Output embeddings for faster predictions"></a>Output embeddings for faster predictions</h3><p>作者提出可以对item embedding向量做预测，使测试结果更具有泛化意义。loss function此时可以定义为embedding的cosine相似度。此时计算量也可以下降： 从原始的H<em>N变为H</em>D，H为hidden layer nums，N为item个数，D为item的embedding size。</p>
<h2 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h2><p>作者提出了2中策略提升原GRU4REC的效果，另外提出了generalised distillation framework来训练一个新的模型，同时将item预测的任务变为预测item embedding。对于直接对item embedding的预测，作者最后也提到，需要优质的item embedding源做label，虽然可以重用上述模型的产出，但是此时的效果又会如何呢？</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ol>
<li><a href="https://arxiv.org/pdf/1511.06939.pdf" target="_blank" rel="noopener">SESSION-BASED RECOMMENDATIONS WITH RECURRENT NEURAL NETWORKS</a></li>
<li><a href="https://alexiskz.files.wordpress.com/2016/06/feature-rnn-paper1.pdf" target="_blank" rel="noopener">Parallel Recurrent Neural Network Architectures for Feature-rich Session-based Recommendations</a></li>
<li><a href="http://ceur-ws.org/Vol-1922/paper11.pdf" target="_blank" rel="noopener">Incorporating Dwell Time in Session-Based Recommendations with Recurrent Neural Networks</a></li>
<li><a href="https://arxiv.org/pdf/1706.04148.pdf" target="_blank" rel="noopener">Personalizing Session-based Recommendations with<br>Hierarchical Recurrent Neural Networks</a></li>
<li><a href="https://web-ainf.aau.at/pub/jannach/files/Conference_RecSys_2017.pdf" target="_blank" rel="noopener">When Recurrent Neural Networks meet the Neighborhood for<br>Session-Based Recommendation</a></li>
<li><a href="https://arxiv.org/pdf/1606.08117.pdf" target="_blank" rel="noopener">Improved Recurrent Neural Networks for Session-based Recommendations</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/24/spark-with-tfrecords/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zoe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据挖掘日常笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/24/spark-with-tfrecords/" itemprop="url">spark_with_tfrecords</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-09-24T17:13:35+08:00">
                2019-09-24
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-09-24T17:49:52+08:00">
                2019-09-24
              </time>
            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  944
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="spark-tensorflow-connector"><a href="#spark-tensorflow-connector" class="headerlink" title="spark-tensorflow-connector"></a>spark-tensorflow-connector</h1><p>spark-tensorflow-connector是tensorflow提供的解决如何利用spark生成tfrecord文件的解决方案</p>
<h2 id="安装与配置"><a href="#安装与配置" class="headerlink" title="安装与配置"></a>安装与配置</h2><ol>
<li>git clone <a href="https://github.com/tensorflow/ecosystem" target="_blank" rel="noopener">https://github.com/tensorflow/ecosystem</a></li>
<li><p>安装并配置maven</p>
<p> 2.1 下载maven压缩包 <a href="http://maven.apache.org/download.cgi" target="_blank" rel="noopener">http://maven.apache.org/download.cgi</a></p>
<p> 2.2 解压缩到指定目录</p>
<p> 2.3 配置～/.bash_profile</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> M2_HOME=/Users/xxx/apache-maven-3.3.3</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$M2_HOME</span>/bin</span><br></pre></td></tr></table></figure>
<p> 2.4 source ～/.bash_profile使配置生效</p>
<p> 2.5 mvn -v 查看maven配置成功</p>
<p> （如果失败，请配置JAVA_HOME）</p>
</li>
<li><p>intellij打开 xx/ecosystem/hadoop 工程， 执行maven clean &amp; install</p>
<p>若出现一下错误</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.9:jar (attach-javadocs) on project template.querylist: MavenReportException: Error while creating archive: Unable to find javadoc command: The environment variable JAVA_HOME is not correctly set. -&gt; [Help 1]</span><br></pre></td></tr></table></figure>
<p>可以修改POM配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">javadocExecutable</span>&gt;</span>$&#123;java.home&#125;/../bin/javadoc<span class="tag">&lt;/<span class="name">javadocExecutable</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>intellij打开 xx/ecosystem/spark/spark-tensorflow-connector工程， 执行maven clean &amp; install 得到最终到spark-tensorflow-connector_2.11-1.10.0.jar</p>
</li>
</ol>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>官方给出的scala example：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xxx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>._;</span><br><span class="line"><span class="keyword">import</span> scala.collection.<span class="type">JavaConverters</span>._;</span><br><span class="line"><span class="keyword">import</span> collection.<span class="type">JavaConversions</span>._</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123; <span class="type">Level</span>, <span class="type">Logger</span> &#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123; <span class="type">DataFrame</span>, <span class="type">Row</span> &#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.catalyst.expressions.<span class="type">GenericRow</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TFRecordsExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="type">Logger</span>.getLogger(<span class="string">"org.apache.spark"</span>).setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</span><br><span class="line">    <span class="type">Logger</span>.getLogger(<span class="string">"org.eclipse.jetty.server"</span>).setLevel(<span class="type">Level</span>.<span class="type">OFF</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder().master(<span class="string">"local[4]"</span>).appName(<span class="string">"tfrecords_examples"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> path = <span class="string">"file/test-output.tfrecord"</span></span><br><span class="line">    <span class="keyword">val</span> testRows: <span class="type">Array</span>[<span class="type">Row</span>] = <span class="type">Array</span>(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">GenericRow</span>(<span class="type">Array</span>[<span class="type">Any</span>](<span class="number">11</span>, <span class="number">1</span>, <span class="number">23</span>L, <span class="number">10.0</span>F, <span class="number">14.0</span>, <span class="type">List</span>(<span class="number">1.0</span>, <span class="number">2.0</span>), <span class="string">"r1"</span>)),</span><br><span class="line">      <span class="keyword">new</span> <span class="type">GenericRow</span>(<span class="type">Array</span>[<span class="type">Any</span>](<span class="number">21</span>, <span class="number">2</span>, <span class="number">24</span>L, <span class="number">12.0</span>F, <span class="number">15.0</span>, <span class="type">List</span>(<span class="number">2.0</span>, <span class="number">2.0</span>), <span class="string">"r2"</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> schema = <span class="type">StructType</span>(<span class="type">List</span>(</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"id"</span>, <span class="type">IntegerType</span>),</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"IntegerCol"</span>, <span class="type">IntegerType</span>),</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"LongCol"</span>, <span class="type">LongType</span>),</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"FloatCol"</span>, <span class="type">FloatType</span>),</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"DoubleCol"</span>, <span class="type">DoubleType</span>),</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"VectorCol"</span>, <span class="type">ArrayType</span>(<span class="type">DoubleType</span>, <span class="literal">true</span>)),</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"StringCol"</span>, <span class="type">StringType</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> rdd = spark.sparkContext.parallelize(testRows)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Save DataFrame as TFRecords</span></span><br><span class="line">    <span class="keyword">val</span> df: <span class="type">DataFrame</span> = spark.createDataFrame(rdd, schema)</span><br><span class="line">    df.write.format(<span class="string">"tfrecords"</span>).option(<span class="string">"recordType"</span>, <span class="string">"SequenceExample"</span>).save(path)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Read TFRecords into DataFrame.</span></span><br><span class="line">    <span class="comment">//The DataFrame schema is inferred from the TFRecords if no custom schema is provided.</span></span><br><span class="line">    <span class="keyword">val</span> importedDf1: <span class="type">DataFrame</span> = spark.read.format(<span class="string">"tfrecords"</span>).option(<span class="string">"recordType"</span>, <span class="string">"SequenceExample"</span>).load(path)</span><br><span class="line">    importedDf1.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Read TFRecords into DataFrame using custom schema</span></span><br><span class="line">    <span class="keyword">val</span> importedDf2: <span class="type">DataFrame</span> = spark.read.format(<span class="string">"tfrecords"</span>).schema(schema).load(path)</span><br><span class="line">    importedDf2.show()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>pom文件：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.xxx.ai<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>tfrecordsProj<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.tensorflow<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-tensorflow-connector_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.16<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-library<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.11.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-compiler<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.12.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-reflect<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.11.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang.modules<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-xml_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang.modules<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-parser-combinators_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>官方给出的python example<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark =  SparkSession.builder.master(<span class="string">"local[4]"</span>).appName(<span class="string">"tfrecords_examples"</span>).getOrCreate()</span><br><span class="line">path = <span class="string">'/Users/linglingsu/Documents/intellij_workspace/tfrecordsProj/file/test-output.tfrecord'</span></span><br><span class="line">fields = [StructField(<span class="string">"id"</span>, IntegerType()), StructField(<span class="string">"IntegerCol"</span>, IntegerType()),</span><br><span class="line">          StructField(<span class="string">"LongCol"</span>, LongType()), StructField(<span class="string">"FloatCol"</span>, FloatType()),</span><br><span class="line">          StructField(<span class="string">"DoubleCol"</span>, DoubleType()), StructField(<span class="string">"VectorCol"</span>, ArrayType(DoubleType(), <span class="literal">True</span>)),</span><br><span class="line">          StructField(<span class="string">"StringCol"</span>, StringType())]</span><br><span class="line">schema = StructType(fields)</span><br><span class="line">df = spark.read.format(<span class="string">"tfrecords"</span>).option(<span class="string">"recordType"</span>, <span class="string">"SequenceExample"</span>).load(path)</span><br><span class="line">df_pandas = df.toPandas()</span><br><span class="line">print(df_pandas.head())</span><br></pre></td></tr></table></figure></p>
<p>运行命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pyspark-submit --jars xxx/ecosystem/spark/spark-tensorflow-connector/target/spark-tensorflow-connector_2.11-1.10.0.jar test.py</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/19/推荐系统-找相似/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zoe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据挖掘日常笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/19/推荐系统-找相似/" itemprop="url">推荐系统-找相似</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-09-19T16:11:10+08:00">
                2019-09-19
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-09-20T15:41:39+08:00">
                2019-09-20
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐/" itemprop="url" rel="index">
                    <span itemprop="name">推荐</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  9
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近做推荐，召回其中的一个策略是采用协同过滤的算法，本来觉得不就是简单的一通计算相似度取topK相似用户做推荐就好嘛！但是真正做起来就要踩“大数据”的坑。</p>
<p>传统的基于协同过滤，核心在于计算相似度找到topK相似用户/物品，无论哪种计算相似度的时间复杂度都会随着用户/物品规模的扩大而呈平方增长，对于实际应用中，用户/物品往往达到千万甚至更多，因此暴力计算相似度显然不可行，这时就需要采用近似计算的方法，损失一部分精度来换取计算的效率。</p>
<p>最开始准备采用Facebook的Faiss框架来计算相似度，但是由于准备用go做服务，Faiss没有官方提供go的接口需要手动编译，而且计算用户相似度时，数据是动态的，用起来不那么方便，因此弃用Faiss转向LSH来计算用户的相似度。下面详述Min hashing和LSH（local sensitive hashing）原理。</p>
<h1 id="Hash-Functions"><a href="#Hash-Functions" class="headerlink" title="Hash Functions"></a>Hash Functions</h1><p>大家应该经常能听到哈希，也用过java类或相似的包来计算哈希值，哈希函数根据hash-key可以产生一个bucket number作为其存储位置，因此可以快速查询。hash table就是根据key-value通过hash function（记为h）得到映射的值进行寻址直接访问的数据结构。</p>
<ol>
<li>对于不同的key得到同样的散列地址，即$k_{1}≠ k_{2}$但$h_{1} = h_{2}$，我们称之为碰撞。</li>
<li>若对于所有的key经过hash function的映射到每一个地址的概率是相等的，则成为均匀散列函数。</li>
</ol>
<h1 id="Min-Hashing"><a href="#Min-Hashing" class="headerlink" title="Min Hashing"></a>Min Hashing</h1><h2 id="Jaccard相似度"><a href="#Jaccard相似度" class="headerlink" title="Jaccard相似度"></a>Jaccard相似度</h2><p>Jaccard index用于计算相似度，是距离的一种度量方式，假设有向量$S_{1}$和$S_{2}$，我们定义<center>$Jaccard(S_{1}, S_{2})=\frac{S_{1}∩S_{2}}{S_{1}∪S_{2}}$</center></p>
<h2 id="Minhash"><a href="#Minhash" class="headerlink" title="Minhash"></a>Minhash</h2><p>Min Hashing是LSH的一种，可以用于快速估计两个向量的相似度。Min Hashing和Jaccard相似度有很大的关系：</p>
<pre><code>对两个向量进行Min Hashing，产生的哈希值相同的概率等于两个向量的Jaccard相似度
                                                            -- (1)
</code></pre><p>通过MinHash得到映射分两步：</p>
<ul>
<li>首先对row进行permutation，每个向量做同样的操作</li>
<li>向量的MinHash值对应permutation后，取值为非零的第一行的row index</li>
</ul>
<p>考虑为什么通过Minhash可以达到上述(1)所说的效果呢？我们举例如下，有四个向量，每个向量有5行（维）（我们可以把列看作User，行看作Item，即User$S_{1}$购买过2，3商品…）：</p>
<p>表1:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>row</th>
<th>$S_{1}$</th>
<th>$S_{2}$</th>
<th>$S_{3}$</th>
<th>$S_{4}$  </th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1       </td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0 </td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1 </td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1 </td>
</tr>
<tr>
<td>4</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0 </td>
</tr>
</tbody>
</table>
</div>
<p>我们看$S_{1}$和$S_{2}$，每一行的取值分三种情况：</p>
<ol>
<li>$S_{1}$和$S_{2}$同为1</li>
<li>$S_{1}$和$S_{2}$一个为0一个为1</li>
<li>$S_{1}$和$S_{2}$同为0</li>
</ol>
<p>由于矩阵通常很稀疏（考虑实际中用户与购买物品的矩阵），因此大部分为情况3，但是1和2决定来Jaccard($S_{1}$,$S_{2}$)和$h\left(S_{1}\right)=h\left(S_{2}\right)$概率，假设情况1有x行，情况2有y行，则$\operatorname{Jaccard}\left(S_{1}, S_{2}\right)=\frac{x}{x+y}$（x相当于$S_{1} \cap S_{2}$，y相当于$S_{1} \cup S_{2}$）,若Permutation是随机的，则$S_{1}$和$S_{2}$从上向下找第一个非零属于情况1的概括为$\frac{x}{x+y}$。 </p>
<h2 id="Min-Hashing-signatures"><a href="#Min-Hashing-signatures" class="headerlink" title="Min Hashing signatures"></a>Min Hashing signatures</h2><p>如何通过Min Hashing产生签名呢？</p>
<p>对向量做m次permutation(m一般为几百或更小，小于原向量长度n)，每一次经过permutation得到minhash记为$h_{1}, h_{2}, \ldots, h_{m}$， 则向量获得的签名可以表示为：<center>$\operatorname{sig}(A)=\left[h_{1}(A), h_{2}(A), \ldots, h_{m}(A)\right]$</center><br>对于一个高维度的向量进行permutation也是非常耗时的，因此可以随机选择m个哈希函数代替permutation。具体做法如下：</p>
<ol>
<li>取m个针对row index的哈希函数$h_{1},h_{2}, \ldots, h_{m}$将原始0,1…n-1映射到0,1…n-1上</li>
<li>记Sig(i,c)为第c列在第i个哈希函数下的MinHash值，初始值记做$\infty$</li>
<li>对于每一行r<ul>
<li>计算$h_{1}(r),h_{2}(r),\ldots,h_{m}(r)$</li>
<li>对于每列c：<ul>
<li>如果c在r行取值为0，忽略</li>
<li>如果c在r行取值为1，则对$i=1,2,…,m$计算Sig(i,c) = Min(Sig(i,c),$h_{i}(r)$)</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>对表1所示数据，我们举例说明Min Hashing签名生成过程，假设我们选择两个哈希函数对row index生成MinHash，如下表2所示：$h_{1}(x) = x+1  \mod 5$, $h_{2}(x) = 3x+1 \mod 5$</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>row</th>
<th>$S_{1}$</th>
<th>$S_{2}$</th>
<th>$S_{3}$</th>
<th>$S_{4}$</th>
<th>x+1 mod 5</th>
<th>3x+1 mod 5</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1       </td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>2</td>
<td>4 </td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>3</td>
<td>2 </td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>4</td>
<td>0 </td>
</tr>
<tr>
<td>4</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>5</td>
<td>3 </td>
</tr>
</tbody>
</table>
</div>
<p>初始时，哈希签名如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>row</th>
<th>$S_{1}$</th>
<th>$S_{2}$</th>
<th>$S_{3}$</th>
<th>$S_{4}$  </th>
</tr>
</thead>
<tbody>
<tr>
<td>$h_{1}$</td>
<td>$\infty$</td>
<td>$\infty$</td>
<td>$\infty$</td>
<td>$\infty$        </td>
</tr>
<tr>
<td>$h_{2}$</td>
<td>$\infty$</td>
<td>$\infty$</td>
<td>$\infty$</td>
<td>$\infty$   </td>
</tr>
</tbody>
</table>
</div>
<p>对于第0行，只有$S_{1}$ 和$S_{4}$为非零，且$h_{1}$和$h_{2}$均为1,则当前签名矩阵变为</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>row</th>
<th>$S_{1}$</th>
<th>$S_{2}$</th>
<th>$S_{3}$</th>
<th>$S_{4}$  </th>
</tr>
</thead>
<tbody>
<tr>
<td>$h_{1}$</td>
<td>1</td>
<td>$\infty$</td>
<td>$\infty$</td>
<td>1       </td>
</tr>
<tr>
<td>$h_{2}$</td>
<td>1</td>
<td>$\infty$</td>
<td>$\infty$</td>
<td>1 </td>
</tr>
</tbody>
</table>
</div>
<p>对于第1行，$S_{3}$为1，对于$h_{1}$和$h_{2}$为2和4，则签名矩阵变为：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>row</th>
<th>$S_{1}$</th>
<th>$S_{2}$</th>
<th>$S_{3}$</th>
<th>$S_{4}$  </th>
</tr>
</thead>
<tbody>
<tr>
<td>$h_{1}$</td>
<td>1</td>
<td>$\infty$</td>
<td>2</td>
<td>1        </td>
</tr>
<tr>
<td>$h_{2}$</td>
<td>1</td>
<td>$\infty$</td>
<td>4</td>
<td>1 </td>
</tr>
</tbody>
</table>
</div>
<p>继续至第2行，$S_{2}$ 和$S_{4}$为非零，对应$h_{1}$和$h_{2}为3和2，$S_{4}$目前的值均为1，小于$h_{1}$，$h_{2}$对应的3和2，则签名矩阵变为：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>row</th>
<th>$S_{1}$</th>
<th>$S_{2}$</th>
<th>$S_{3}$</th>
<th>$S_{4}$  </th>
</tr>
</thead>
<tbody>
<tr>
<td>$h_{1}$</td>
<td>1</td>
<td>3</td>
<td>2</td>
<td>1        </td>
</tr>
<tr>
<td>$h_{2}$</td>
<td>1</td>
<td>2</td>
<td>4</td>
<td>1 </td>
</tr>
</tbody>
</table>
</div>
<p>…</p>
<p>最后扫描完第4行，最后得到签名矩阵为：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>row</th>
<th>$S_{1}$</th>
<th>$S_{2}$</th>
<th>$S_{3}$</th>
<th>$S_{4}$  </th>
</tr>
</thead>
<tbody>
<tr>
<td>$h_{1}$</td>
<td>1</td>
<td>3</td>
<td>0</td>
<td>1       </td>
</tr>
<tr>
<td>$h_{2}$</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>0 </td>
</tr>
</tbody>
</table>
</div>
<p>通过上述过程可以看到，实际的$Jaccard(S_{1},S_{4})=2/3$，但通过签名计算得到的$Jaccard(S_{1},S_{4})=1$，上述结果是由于示例只选择了两个哈希函数，在实际应用中，会选择更多的哈希函数并且向量数往往在百万千万级，这时就会比较相近了。</p>
<h1 id="Local-Sensitive-Hashing-LSH"><a href="#Local-Sensitive-Hashing-LSH" class="headerlink" title="Local Sensitive Hashing(LSH)"></a>Local Sensitive Hashing(LSH)</h1><p>经过Min Hashing，我们可以实现数据降维并保证降维后的数据保持原空间的相似度，降低了在物品维度很高时计算相似度的时间复杂度，但是当用户数巨大时，计算两两相似度仍旧需要很高的时间开销，如何进一步降低寻找相似用户的复杂度，就需要LSH这样一个近似算法来实现。</p>
<p>LSH常见的做法是经过多次哈希将相似的向量散列到相同的桶中，检索时，我们只需要考虑相同桶中的任意对作为候选集即可。我们称不相似的向量被散列到相同的桶样本为false positive，相似的向量被散列到不同到桶中的样本称为false negetive。</p>
<p>在有来Min Hashing签名的基础上，一个有效的办法是将签名分段，我们称之为band。如下图所示：<br><img src="/2019/09/19/推荐系统-找相似/1.jpg" alt="1"></p>
<p>每个签名都被分成4段，向量的签名散列到对应的band上，如果band相同的越多，则其相似度越高。我们可以通过band获取candidate，计算candidate相似用户的相似度就好了。</p>
<h2 id="如何选择band数？"><a href="#如何选择band数？" class="headerlink" title="如何选择band数？"></a>如何选择band数？</h2><p>假设我们有b和band，每个band有r行，即总的Min Hashing签名长度为b*r，假设两个向量的Jaccard相似度为s，则：</p>
<ol>
<li>对于某一个band，所有行都相等的概率为：$s^r$</li>
<li>对于某一个band，至少有一行不同的概率为：$1 - s^r$</li>
<li>对所有band，至少有一行不同的概率为： $(1 - s^r)^b$</li>
<li>至少有一个band的所有行都相等的概率为： $1- (1 - s^r)^b$，即两个用户成为candidate的概率</li>
</ol>
<p>上述概率在r，b不同值时为一个S曲线，如当r=6，b=100时的曲线如下图：</p>
<p><img src="/2019/09/19/推荐系统-找相似/2.jpg" alt="2"></p>
<p>我们定义超过0.5的概率就有可能成为candidate，此时对应的相似度称为threshold:<center>$threshold \approx (\frac{1}{b})^{(\frac{1}{r})}$</center></p>
<p>在实际应用中，我们需要先确定最小相似度，即相似度大于多少我们认为可以作为candidate，然后确定哈希签名的长度进而可以确定b和r。我们需要考虑的是：</p>
<ul>
<li>我们想要尽可能少出现false negative，我们需要选择b和r使得thresh&lt; 我们定义的最小相似度。</li>
<li>如果要保证计算速度快并尽可能少出现false positive，我们需要选择b和r使得thresh&gt;最小相似度。</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献:"></a>参考文献:</h1><ol>
<li>Mining of massive datasets；  Jeffrey D. Ullman Anand Rajaraman, Jure Leskovec.</li>
<li><a href="https://zhuanlan.zhihu.com/p/46164294" target="_blank" rel="noopener">大规模数据的相似度计算：LSH算法</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/20/推荐之FM-FFM-Deep-FM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zoe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据挖掘日常笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/20/推荐之FM-FFM-Deep-FM/" itemprop="url">推荐之FM/FFM/Deep_FM</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-20T17:02:29+08:00">
                2019-08-20
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-08-20T17:07:35+08:00">
                2019-08-20
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐/" itemprop="url" rel="index">
                    <span itemprop="name">推荐</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  976
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h1><p>FM常用于CTR估计，能够处理稀疏数据下的特征组合的问题。</p>
<h2 id="FM原理"><a href="#FM原理" class="headerlink" title="FM原理"></a>FM原理</h2><p>一般的线性模型不考虑特征之间的关系，公式定义如下：<br>    <center> $y=w_{0}+\sum_{i=1}^{n}x_{i}w_{i}$         ...(1) </center><br>为了表达特征之间的相关性，利用多项式函数，定义如下：<br>    <center>$y=w_{0}+\sum_{i=1}^{n}x_{i}w_{i}+\sum_{i=1}^{n}\sum_{j=i+1}^{n}w_{i,j
}x_{i}x_{j}$         ...(2)</center><br>如上述公式，定义的二阶特征参数有$\frac{n*(n-1)}{2}$个，同时当特征非常稀疏且纬度高时，不仅时间复杂度在增加，同时由于稀疏的特征，很多二阶特征系数通常学习不到。<br>为了解决上述的问题，FM对每个特征引入辅助向量$V_{i} = [v_{i1},v_{i2},…v_{ik}]^{T}$，此时每个特征学习到一个k纬向量而不是一个值，从而解决数据稀疏下到特征组合问题。此时模型如下：<center>$y = w_{0}+\sum_{i=0}^{n}w_{i}x_{i} + \sum_{i=1}^{n}\sum_{j=i+1}^{n}<v_{i},v_{j}>x_{i}x_{j}$        ...(3) </v_{i},v_{j}></center><br>其中k表示辅助向量的纬度，为超参数。上述表达式的时间复杂度为$kn^{2}$。为降低时间复杂度，对(3)式最后一项做如下变化：<br>$\sum _ { i = 1 } ^ { n } \sum _ { j = i + 1 } ^ { n } &lt; V _ { i } , V _ { j } &gt; x _ { i } x _ { j }$<br>$= \frac { 1 } { 2 } \sum _ { i = 1 } ^ { n } \sum _ { j = 1 } ^ { n } &lt; V _ { i } , V _ { j } &gt; x _ { i } x _ { j } - \frac { 1 } { 2 } \sum _ { i = 1 } ^ { n } &lt; V _ { i } , V _ { i } &gt; x _ { i } x _ { i }$<br>$=\frac{1}{2}(\sum_{i=1}^{n}\sum_{j=1}^{n}\sum_{f=1}^{k}v_{if}v_{jf}x_{i}x_{j} - \sum_{i=1}^{n}\sum_{f=1}^{k}v_{if}v_{if}x_ix_i)$<br>$=\frac{1}{2}\sum_{f=1}^{k}((\sum_{i=1}^{n}v_{if}x_{i})^2 - \sum_{i=1}^{n}(v_{if}x_i)^2)$</p>
<p>通过上述变化可以发现，将公式(3)的时间复杂度从$kn^{2}$降低为$kn$。</p>
<h2 id="FM优点"><a href="#FM优点" class="headerlink" title="FM优点"></a>FM优点</h2><ol>
<li>通过引入辅助向量，能够解决稀疏数据的特征组合问题。</li>
<li>模型的时间复杂度为线性的（kn）。</li>
</ol>
<h1 id="FFM"><a href="#FFM" class="headerlink" title="FFM"></a>FFM</h1><p>FFM(Field-aware Factorization Machine)为FM的改进版，区别是FM的辅助向量为K维，而FFM的辅助向量为F*K维，其中F为field个数。对应的FFM模型如下：<br>    <center>$y = w_{0}+\sum_{i=0}^{n}w_{i}x_{i} + \sum_{i=1}^{n}\sum_{j=i+1}^{n}<v_{i,f_{j}},v_{j,f_{i}}>x_{i}x_{j}$        ...(3) </v_{i,f_{j}},v_{j,f_{i}}></center><br>    其中$f_{i,f_{j}}$为i特征属于$f_{j}$下的辅助向量。由于FFM不能按照(3)进行化简，因此时间复杂度为$kn^{2}$。</p>
<h2 id="FFM优缺点"><a href="#FFM优缺点" class="headerlink" title="FFM优缺点"></a>FFM优缺点</h2><ol>
<li>与FM相比FFM具有field感知能力，模型能力更强。</li>
<li>与FM相比，辅助向量变为F*K维学习参数变为FM的F倍。</li>
<li>与FM相比，时间复杂度高。</li>
</ol>
<h1 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h1><p>由于FM/FFM使用的是一阶和二阶特征，为了学习更高阶特征，Huifeng Guo等人提出了DeepFM。<br>与DeepFM相似的模型有FNN，PNN，Wide&amp;deep，模型结构如下图所示：<br><img src="/2019/08/20/推荐之FM-FFM-Deep-FM/1.png" alt="1"><br>FNN使用预训练好的权重作为NN的输入，只能得到高阶特征组合，PNN则是在embedding层和第一层隐藏层中加入了product操作。Wide&amp;deep 的提出则是为了综合低阶特征组合和高阶特征组合，wide部分多为专家经过特征工程得到的低阶组合特征，而deep部分则通过NN网络学习到高阶特征。<br>DeepFM不仅可以达到Wide&amp;deep同时学习低阶特征组合和高阶特征组合的效果，同时想比于Wide&amp;deep网络的优点是，不需要专家经过特征组合筛选特征。网络结果如下：<br><img src="/2019/08/20/推荐之FM-FFM-Deep-FM/2.png" alt="2"></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ol>
<li>DeepFM: A Factorization-Machine based Neural Network for CTR Prediction   [<a href="https://arxiv.org/pdf/1703.04247.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.04247.pdf</a>]</li>
<li>推荐系统召回四模型之：全能的FM模型<br>[<a href="https://zhuanlan.zhihu.com/p/58160982" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/58160982</a>]</li>
<li>CTR预估算法之FM, FFM, DeepFM及实践<br>[<a href="https://blog.csdn.net/John_xyz/article/details/78933253" target="_blank" rel="noopener">https://blog.csdn.net/John_xyz/article/details/78933253</a>]</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/15/TF的三种模型的保存与加载方式/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zoe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据挖掘日常笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/15/TF的三种模型的保存与加载方式/" itemprop="url">TF的三种模型的保存与加载方式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-15T16:14:26+08:00">
                2019-08-15
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-08-15T20:53:02+08:00">
                2019-08-15
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deeplearning/" itemprop="url" rel="index">
                    <span itemprop="name">Deeplearning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deeplearning/Tensorflow/" itemprop="url" rel="index">
                    <span itemprop="name">Tensorflow</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  10
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="TF的三种模型的保存与加载方法"><a href="#TF的三种模型的保存与加载方法" class="headerlink" title="TF的三种模型的保存与加载方法"></a>TF的三种模型的保存与加载方法</h1><p>当我们训练完一波模型，准备把模型应用于生产环境时，我们需要在生产环境部署预测的model，此时就涉及到如何把我们训练好的model重新加载以及处于效率的考虑，用什么方法更好的部署模型。因此我们来谈谈常见的三种模型的保存与加载方法。</p>
<ul>
<li>Checkpoint： 知道模型结构，单纯保存变量  </li>
<li>SavedModel： 不知道模型结构，保存模型和变量</li>
<li>Freeze pb： 不需要再改变量，只要常量化的模型（“冻结”）</li>
</ul>
<h2 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h2><p>第一种必然是大家最为熟悉的checkpoint的方式，通常在模型训练时，我们通过saver=tf.train.saver()定义saver，在session中通过saver.save()保存模型中的变量。此时我们<strong>只是单纯保存了变量而没有对模型本身做任何保存</strong>，此时恢复模型需要有模型对应的源代码，因此当我们需要在C++中恢复模型，只能用C++把模型的代码复写一遍。<br>保存:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a = tf.placeholder(dtype=tf.float32, shape=[<span class="number">2</span>,<span class="number">2</span>], name=<span class="string">'a'</span>)</span><br><span class="line">b = tf.placeholder(dtype=tf.float32, shape=[<span class="number">2</span>,<span class="number">2</span>], name=<span class="string">'b'</span>)</span><br><span class="line"></span><br><span class="line">w = tf.get_variable(name=<span class="string">'w'</span>, shape=[<span class="number">2</span>, <span class="number">2</span>], initializer=tf.ones_initializer())</span><br><span class="line">c = tf.add(tf.add(a, b), w)</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    result = sess.run(c, feed_dict=&#123;a:[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">3</span>]], b:[[<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>]]&#125;)</span><br><span class="line">    saver.save(sess, <span class="string">'./saved_model/model.ckpt'</span>)</span><br><span class="line"></span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[4. 6.]</span><br><span class="line"> [7. 9.]]</span><br></pre></td></tr></table></figure>
<p>加载：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a = tf.placeholder(dtype=tf.float32, shape=[<span class="number">2</span>, <span class="number">2</span>], name=<span class="string">'a'</span>)</span><br><span class="line">b = tf.placeholder(dtype=tf.float32, shape=[<span class="number">2</span>, <span class="number">2</span>], name=<span class="string">'b'</span>)</span><br><span class="line"></span><br><span class="line">w = tf.get_variable(name=<span class="string">'w'</span>, shape=[<span class="number">2</span>, <span class="number">2</span>], initializer=tf.ones_initializer())</span><br><span class="line">c = tf.add(tf.add(a, b), w)</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">'./saved_model/model.ckpt'</span>)</span><br><span class="line">    result = sess.run(c, feed_dict=&#123;a: [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>]], b: [[<span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>]]&#125;)</span><br><span class="line"></span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[4. 6.]</span><br><span class="line"> [7. 9.]]</span><br></pre></td></tr></table></figure>
<p>可以看到，通过restore我们可以得到同样的结果。</p>
<h2 id="SavedModel"><a href="#SavedModel" class="headerlink" title="SavedModel"></a>SavedModel</h2><p>TF官网介绍说SavedModel是一种独立于语言而且可以恢复的序列化格式，使较高级别的系统和工具可以创建，使用和转换Tensorflow模型。常见的两种与SavedModel交互的方式包括tf.saved_model API 和tf.estimator.Estimator。</p>
<h3 id="tf-saved-model-API"><a href="#tf-saved-model-API" class="headerlink" title="tf.saved_model API"></a>tf.saved_model API</h3><h4 id="保存方法1-使用tf-saved-model-simple-save"><a href="#保存方法1-使用tf-saved-model-simple-save" class="headerlink" title="保存方法1:使用tf.saved_model.simple_save"></a>保存方法1:使用tf.saved_model.simple_save</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a = tf.placeholder(dtype=tf.float32, shape=[<span class="number">2</span>, <span class="number">2</span>], name=<span class="string">'a'</span>)</span><br><span class="line">b = tf.placeholder(dtype=tf.float32, shape=[<span class="number">2</span>, <span class="number">2</span>], name=<span class="string">'b'</span>)</span><br><span class="line"></span><br><span class="line">w = tf.get_variable(name=<span class="string">'w'</span>, shape=[<span class="number">2</span>, <span class="number">2</span>], initializer=tf.ones_initializer())</span><br><span class="line">c = tf.add(tf.add(a, b), w)</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">    tf.saved_model.simple_save(session=sess,</span><br><span class="line">                               export_dir=<span class="string">'./saved_model/pb/1'</span>,</span><br><span class="line">                               inputs=&#123;<span class="string">'a'</span>: a, <span class="string">'b'</span>: b&#125;,</span><br><span class="line">                               outputs=&#123;<span class="string">'c'</span>: c&#125;)</span><br></pre></td></tr></table></figure>
<p>此时，我们可以在saved_model/pb下看到如下文件结构：</p>
<pre><code> --  saved_model
    |--  pb
        |-- 1
            |-- saved_model.pb
            |-- variables
                |-- variables.data-00000-of-00001
                |-- variables.index
</code></pre><h4 id="保存方法2-通过SavedModelBuilder构建"><a href="#保存方法2-通过SavedModelBuilder构建" class="headerlink" title="保存方法2:通过SavedModelBuilder构建"></a>保存方法2:通过SavedModelBuilder构建</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a = tf.placeholder(dtype=tf.float32, shape=[<span class="number">2</span>, <span class="number">2</span>], name=<span class="string">'a'</span>)</span><br><span class="line">b = tf.placeholder(dtype=tf.float32, shape=[<span class="number">2</span>, <span class="number">2</span>], name=<span class="string">'b'</span>)</span><br><span class="line"></span><br><span class="line">w = tf.get_variable(name=<span class="string">'w'</span>, shape=[<span class="number">2</span>, <span class="number">2</span>], initializer=tf.ones_initializer())</span><br><span class="line">c = tf.add(tf.add(a, b), w)</span><br><span class="line">saver =tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># sess.run(tf.global_variables_initializer())</span></span><br><span class="line">    saver.restore(sess, <span class="string">'./saved_model/model.ckpt'</span>)</span><br><span class="line">    builder = tf.saved_model.builder.SavedModelBuilder(<span class="string">"./saved_model/pb/2"</span>)</span><br><span class="line">    inputs = &#123;<span class="string">'a'</span>: tf.saved_model.utils.build_tensor_info(a),</span><br><span class="line">              <span class="string">'b'</span>: tf.saved_model.utils.build_tensor_info(b)&#125;</span><br><span class="line">    output = &#123;<span class="string">'c'</span>: tf.saved_model.utils.build_tensor_info(c)&#125;</span><br><span class="line"></span><br><span class="line">    prediction_signature = tf.saved_model.signature_def_utils.build_signature_def(</span><br><span class="line">        inputs=inputs,</span><br><span class="line">        outputs=output,</span><br><span class="line">        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME</span><br><span class="line">    )</span><br><span class="line">    builder.add_meta_graph_and_variables(</span><br><span class="line">        sess,</span><br><span class="line">        [tf.saved_model.tag_constants.SERVING],</span><br><span class="line">        &#123;tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_signature&#125;</span><br><span class="line">    )</span><br><span class="line">    builder.save()</span><br></pre></td></tr></table></figure>
<h4 id="通过saved-model-cli命令查看SavedModel"><a href="#通过saved-model-cli命令查看SavedModel" class="headerlink" title="通过saved_model_cli命令查看SavedModel"></a>通过saved_model_cli命令查看SavedModel</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saved_model_cli show --dir /Users/xxx/Documents/pycharm_workspace/test_python/saved_model/pb/1 --all</span><br></pre></td></tr></table></figure>
<p>可以得到如下结果：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">MetaGraphDef with tag-set: <span class="string">'serve'</span> contains the following SignatureDefs:</span><br><span class="line"></span><br><span class="line">signature_def[<span class="string">'serving_default'</span>]:</span><br><span class="line">  The given SavedModel SignatureDef contains the following input(s):</span><br><span class="line">    inputs[<span class="string">'a'</span>] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (2, 2)</span><br><span class="line">        name: a:0</span><br><span class="line">    inputs[<span class="string">'b'</span>] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (2, 2)</span><br><span class="line">        name: b:0</span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[<span class="string">'c'</span>] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (2, 2)</span><br><span class="line">        name: Add_1:0</span><br><span class="line">  Method name is: tensorflow/serving/predict</span><br></pre></td></tr></table></figure></p>
<h4 id="加载方法1-通过tf-saved-model-loader-load加载"><a href="#加载方法1-通过tf-saved-model-loader-load加载" class="headerlink" title="加载方法1: 通过tf.saved_model.loader.load加载"></a>加载方法1: 通过tf.saved_model.loader.load加载</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">export_dir = <span class="string">'./saved_model/pb/2'</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    meta_graph_def = tf.saved_model.loader.load(sess, [<span class="string">'serve'</span>],</span><br><span class="line">                                                export_dir)</span><br><span class="line">    a = sess.graph.get_tensor_by_name(<span class="string">'a:0'</span>)</span><br><span class="line">    b = sess.graph.get_tensor_by_name(<span class="string">'b:0'</span>)</span><br><span class="line"></span><br><span class="line">    c = sess.graph.get_tensor_by_name(<span class="string">'Add_1:0'</span>)</span><br><span class="line">    print(sess.run(c, feed_dict=&#123;a: [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>]], b: [[<span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>]]&#125;))</span><br></pre></td></tr></table></figure>
<h4 id="加载方法2-通过tf-contrib-predictor-from-saved-model"><a href="#加载方法2-通过tf-contrib-predictor-from-saved-model" class="headerlink" title="加载方法2: 通过tf.contrib.predictor.from_saved_model"></a>加载方法2: 通过tf.contrib.predictor.from_saved_model</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">export_dir = <span class="string">'./saved_model/pb/2'</span></span><br><span class="line">predictor_fn = tf.contrib.predictor.from_saved_model(</span><br><span class="line">    export_dir=export_dir,</span><br><span class="line">    signature_def_key=<span class="string">"serving_default"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">output = predictor_fn(&#123;<span class="string">'a'</span>: [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>]],</span><br><span class="line">                       <span class="string">'b'</span>: [[<span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>]]</span><br><span class="line">                       &#125;)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure>
<h3 id="结合tf-estimator-Estimator使用"><a href="#结合tf-estimator-Estimator使用" class="headerlink" title="结合tf.estimator.Estimator使用"></a>结合tf.estimator.Estimator使用</h3><h4 id="保存方法"><a href="#保存方法" class="headerlink" title="保存方法"></a>保存方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">serving_input_receiver_fn</span><span class="params">()</span>:</span></span><br><span class="line">    feature_spec = &#123;<span class="string">'a'</span>: tf.FixedLenFeature([<span class="number">2</span>,<span class="number">2</span>], tf.float32),</span><br><span class="line">                    <span class="string">'b'</span>: tf.FixedLenFeature([<span class="number">2</span>,<span class="number">2</span>], tf.float32)&#125;</span><br><span class="line"></span><br><span class="line">    serialized_tf_example = tf.placeholder(dtype=tf.string,</span><br><span class="line">                                           shape=[<span class="number">1</span>],</span><br><span class="line">                                           name=<span class="string">'input_example_tensor'</span>)</span><br><span class="line">    receiver_tensors = &#123;<span class="string">'examples'</span>: serialized_tf_example&#125;</span><br><span class="line">    features = tf.parse_example(serialized_tf_example, feature_spec)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.estimator.export.ServingInputReceiver(features, receiver_tensors)</span><br><span class="line"></span><br><span class="line">estimator.export_savedmodel(<span class="string">'saved_model'</span>, serving_input_receiver_fn)</span><br></pre></td></tr></table></figure>
<h4 id="通过tf-serving部署服务访问"><a href="#通过tf-serving部署服务访问" class="headerlink" title="通过tf-serving部署服务访问"></a>通过tf-serving部署服务访问</h4><ul>
<li><p>部署server端：</p>
<ul>
<li>基于Dockerfile 创建镜像：<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu:<span class="number">18.04</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Install general packages</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp; apt-get install -y \</span></span><br><span class="line"><span class="bash">        curl \</span></span><br><span class="line"><span class="bash">        libcurl3-dev \</span></span><br><span class="line"><span class="bash">        unzip \</span></span><br><span class="line"><span class="bash">        wget \</span></span><br><span class="line"><span class="bash">        &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apt-get clean &amp;&amp; \</span></span><br><span class="line"><span class="bash">    rm -rf /var/lib/apt/lists/*</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Previous Installation of tensorflow-model-server (BROKEN RECENTLY)</span></span><br><span class="line"><span class="comment">#RUN echo "deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal" | tee /etc/apt/sources.list.d/tensorflow-serving.list \</span></span><br><span class="line"><span class="comment">#    &amp;&amp; curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add - \</span></span><br><span class="line"><span class="comment">#    &amp;&amp; apt-get update &amp;&amp; apt-get install tensorflow-model-server</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># New installation of tensorflow-model-server</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> TEMP_DEB=<span class="string">"<span class="variable">$(mktemp)</span>"</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; wget -O <span class="string">"<span class="variable">$TEMP_DEB</span>"</span> <span class="string">'http://storage.googleapis.com/tensorflow-serving-apt/pool/tensorflow-model-server-1.12.0/t/tensorflow-model-server/tensorflow-model-server_1.12.0_all.deb'</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; dpkg -i <span class="string">"<span class="variable">$TEMP_DEB</span>"</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; rm -f <span class="string">"<span class="variable">$TEMP_DEB</span>"</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># gRPC port</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8500</span></span><br><span class="line"><span class="comment"># REST API port</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8501</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Serve the model when the container starts</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> tensorflow_model_server \</span></span><br><span class="line"><span class="bash">--port=8500 \</span></span><br><span class="line"><span class="bash">--rest_api_port=8501 \</span></span><br><span class="line"><span class="bash">--model_name=<span class="string">"<span class="variable">$MODEL_NAME</span>"</span> \</span></span><br><span class="line"><span class="bash">--model_base_path=<span class="string">"<span class="variable">$MODEL_PATH</span>"</span></span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>运行如下命令创建镜像：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build --rm -f Dockerfile -t tensorflow-serving-example:0.1 .</span><br></pre></td></tr></table></figure>
<ul>
<li><p>创建临时目录保存savedModel</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p ./saved_model/dkt/1</span><br><span class="line">cp -R ./saved_model/pb/* ./saved_model/<span class="built_in">test</span>/1</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动容器</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it -v /home/xxx/tf_serving/saved_model/:/models -e MODEL_NAME=<span class="built_in">test</span> -e MODEL_PATH=/models/<span class="built_in">test</span> -p 8500:8500 -p 8501:8501 --name tensorflow-serving-example tensorflow-serving-example:0.1</span><br></pre></td></tr></table></figure>
<p>至此，server已启动，运行client进行测试  </p>
</li>
</ul>
</li>
<li><p>client</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.util <span class="keyword">import</span> make_tensor_proto</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> predict_pb2</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> prediction_service_pb2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(host, port, model, signature_name)</span>:</span></span><br><span class="line">    channel = grpc.insecure_channel(<span class="string">'&#123;host&#125;:&#123;port&#125;'</span>.format(host=host, port=port))</span><br><span class="line">    stub = prediction_service_pb2.PredictionServiceStub(channel)</span><br><span class="line">    start = time.time()</span><br><span class="line">    <span class="comment"># Call classification model to make prediction</span></span><br><span class="line">    request = predict_pb2.PredictRequest()</span><br><span class="line">    request.model_spec.name = model</span><br><span class="line">    request.model_spec.signature_name = signature_name</span><br><span class="line"></span><br><span class="line">    feature = &#123;&#125;</span><br><span class="line">    feature[<span class="string">'a'</span>] = tf.train.Feature(float_list=tf.train.FloatList(value=[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]))</span><br><span class="line">    feature[<span class="string">'b'</span>] = tf.train.Feature(float_list=tf.train.FloatList(value=[[<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>]]]))</span><br><span class="line">    example = tf.train.Example(</span><br><span class="line">        features=tf.train.Features(</span><br><span class="line">            feature=feature</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    request.inputs[<span class="string">'examples'</span>].CopyFrom(make_tensor_proto([example.SerializeToString()], shape=[<span class="number">1</span>]))</span><br><span class="line">    result = stub.Predict(request, <span class="number">10.0</span>)  <span class="comment"># 10 secs timeout</span></span><br><span class="line"></span><br><span class="line">    end = time.time()</span><br><span class="line">    time_diff = end - start</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reference:</span></span><br><span class="line">    <span class="comment"># How to access nested values</span></span><br><span class="line">    <span class="comment"># https://stackoverflow.com/questions/44785847/how-to-retrieve-float-val-from-a-predictresponse-object</span></span><br><span class="line">    <span class="comment"># print(result)</span></span><br><span class="line">    result = result.outputs[<span class="string">'predict'</span>].float_val</span><br><span class="line">    print(result)</span><br><span class="line">    print(<span class="string">'predict shape &#123;&#125;'</span>.format(len(result)))</span><br><span class="line">    print(<span class="string">'time elapased: &#123;&#125;'</span>.format(time_diff))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">'--host'</span>, help=<span class="string">'Tensorflow server host name'</span>, default=<span class="string">'10.8.8.71'</span>, type=str)</span><br><span class="line">    parser.add_argument(<span class="string">'--port'</span>, help=<span class="string">'Tensorflow server port number'</span>, default=<span class="number">8500</span>, type=int)</span><br><span class="line">    parser.add_argument(<span class="string">'--model'</span>, help=<span class="string">'model name'</span>, default=<span class="string">'dkt'</span>, type=str)</span><br><span class="line">    parser.add_argument(<span class="string">'--signature_name'</span>, help=<span class="string">'Signature name of saved TF model'</span>,</span><br><span class="line">                        default=<span class="string">'serving_default'</span>, type=str)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    run(args.host, args.port, args.model, args.signature_name)</span><br></pre></td></tr></table></figure>
<h2 id="Freeze-pb"><a href="#Freeze-pb" class="headerlink" title="Freeze pb"></a>Freeze pb</h2><p>当不再需要改变变量，只要常量化当模型时，我们可以采用freeze pb的方式。可以用在不同语言部署的场景下，好处是除了可以冻结模型外，还可以指定剔除某些多余的节点。</p>
<h3 id="冻结"><a href="#冻结" class="headerlink" title="冻结"></a>冻结</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">input_checkpoint = <span class="string">'./saved_model'</span></span><br><span class="line">output_graph = <span class="string">'./saved_model/pb/4/saved_model.pb'</span></span><br><span class="line"><span class="comment"># 指定输出的节点名称,该节点名称必须是原模型中存在的节点</span></span><br><span class="line">output_node_names = <span class="string">"Add_1"</span></span><br><span class="line"><span class="comment"># saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=True)</span></span><br><span class="line"></span><br><span class="line">graph = tf.Graph()  <span class="comment"># 获得默认的图</span></span><br><span class="line"><span class="keyword">with</span> graph.as_default() <span class="keyword">as</span> g:</span><br><span class="line">    a = tf.placeholder(dtype=tf.float32, shape=[<span class="number">2</span>, <span class="number">2</span>], name=<span class="string">'a'</span>)</span><br><span class="line">    b = tf.placeholder(dtype=tf.float32, shape=[<span class="number">2</span>, <span class="number">2</span>], name=<span class="string">'b'</span>)</span><br><span class="line"></span><br><span class="line">    w = tf.get_variable(name=<span class="string">'w'</span>, shape=[<span class="number">2</span>, <span class="number">2</span>], initializer=tf.ones_initializer())</span><br><span class="line">    c = tf.add(tf.add(a, b), w)</span><br><span class="line">    <span class="comment"># Define saver &amp; Load checkpoint</span></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=graph) <span class="keyword">as</span> sess:</span><br><span class="line">    ckpt = tf.train.get_checkpoint_state(input_checkpoint)</span><br><span class="line">    <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">        print(<span class="string">'restore True...'</span>)</span><br><span class="line">        saver.restore(sess, ckpt.model_checkpoint_path)  <span class="comment"># 恢复图并得到数据</span></span><br><span class="line">    <span class="comment"># for op in graph.get_operations():</span></span><br><span class="line">    <span class="comment">#     print(op.name, op.values())</span></span><br><span class="line">    input_graph_def = graph.as_graph_def()  <span class="comment"># 返回一个序列化的图代表当前的图</span></span><br><span class="line">    output_graph_def = tf.graph_util.convert_variables_to_constants(  <span class="comment"># 模型持久化，将变量值固定</span></span><br><span class="line">        sess=sess,</span><br><span class="line">        input_graph_def=input_graph_def,  <span class="comment"># 等于:sess.graph_def</span></span><br><span class="line">        output_node_names=output_node_names.split(<span class="string">","</span>))  <span class="comment"># 如果有多个输出节点，以逗号隔开</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.gfile.GFile(output_graph, <span class="string">"wb"</span>) <span class="keyword">as</span> f:  <span class="comment"># 保存模型</span></span><br><span class="line">        f.write(output_graph_def.SerializeToString())  <span class="comment"># 序列化输出</span></span><br><span class="line">    print(<span class="string">"%d ops in the final graph."</span> % len(output_graph_def.node))  <span class="comment"># 得到当前图有几个操作节点</span></span><br></pre></td></tr></table></figure>
<p>运行上述程序，可在./saved_model/pb/4/下看到saved_model.pb文件。</p>
<h3 id="加载pb"><a href="#加载pb" class="headerlink" title="加载pb"></a>加载pb</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">dir = <span class="string">'./saved_model/pb/4/saved_model.pb'</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(<span class="string">"load graph"</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.gfile.FastGFile(dir, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        graph_def = tf.GraphDef()</span><br><span class="line">    graph_def.ParseFromString(f.read())</span><br><span class="line">    sess.graph.as_default()</span><br><span class="line">    tf.import_graph_def(graph_def, name=<span class="string">''</span>)</span><br><span class="line">    return_elements = [<span class="string">u'a:0'</span>, <span class="string">u'b:0'</span>, <span class="string">u'Add_1:0'</span>]</span><br><span class="line">    return_elements = tf.import_graph_def(graph_def,</span><br><span class="line">                                            return_elements=return_elements)</span><br><span class="line">    a, b, c = return_elements[<span class="number">0</span>], return_elements[<span class="number">1</span>], return_elements[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    feed_dict_testing = &#123;a: [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]],</span><br><span class="line">                            b: [[<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>]],</span><br><span class="line"></span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">    result = sess.run(c, feed_dict=feed_dict_testing)</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure>
<p>以上就是常见的TF的模型保存及对应的加载方法～</p>
<h1 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h1><ol>
<li><a href="https://ggaaooppeenngg.github.io/zh-CN/2019/03/03/tf-%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E5%86%BB%E7%BB%93/" target="_blank" rel="noopener">tensorflow 模型的存档、保存、冻结、优化</a></li>
<li><a href="https://medium.com/@yuu.ishikawa/introduction-to-restful-api-with-tensorflow-serving-9c60969b5b95" target="_blank" rel="noopener">Introduction to RESTful API with Tensorflow Serving</a></li>
<li><a href="https://github.com/yu-iskw/tensorflow-serving-example/blob/master/python/train/mnist_premodeled_estimator.py" target="_blank" rel="noopener">tensorflow-serving-example</a></li>
<li><a href="https://www.tensorflow.org/guide/saved_model?hl=zh-cn" target="_blank" rel="noopener">tensorflow 官方文档</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/14/word2vec/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zoe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据挖掘日常笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/14/word2vec/" itemprop="url">word2vec</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-14T12:30:39+08:00">
                2019-08-14
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-08-20T17:02:47+08:00">
                2019-08-20
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deeplearning/" itemprop="url" rel="index">
                    <span itemprop="name">Deeplearning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deeplearning/NN/" itemprop="url" rel="index">
                    <span itemprop="name">NN</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  0
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/13/doc2vec/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zoe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据挖掘日常笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/13/doc2vec/" itemprop="url">doc2vec</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-13T18:55:31+08:00">
                2019-08-13
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-09-20T15:32:29+08:00">
                2019-09-20
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deeplearning/" itemprop="url" rel="index">
                    <span itemprop="name">Deeplearning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  950
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Doc2vec"><a href="#Doc2vec" class="headerlink" title="Doc2vec"></a>Doc2vec</h1><p>常用于短文本向量化的方法包括：</p>
<ul>
<li>Bag of words</li>
<li>LDA</li>
<li>Average word vectors</li>
<li>tfidf-weighting word vector</li>
</ul>
<p>上述方法存在公共的问题是没有考虑单词的顺序。而本文介绍的doc2vec是2014年谷歌的两位大牛<a href="https://cs.stanford.edu/~quocle/paragraph_vector.pdf" target="_blank" rel="noopener">Quoc Le 和 Tomas Mikolov</a>提出的。文章提出一种无监督学习模型通过预测句子/段落中word来得到句子/段落/文档的向量表示。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><h3 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h3><p>文章提出的得到句子/段落/文档向量的方法是受到word2vec的启发，因此先回顾一下word2vec。如下图所示，word2vec是通过给定单词预测另一个单词，如CBOW根据前后词预测中间词，以及Skip-gram根据中间词预测前后词。<br><img src="/2019/08/13/doc2vec/1.jpg" alt="1"><br>在模型中，每个词都用唯一的向量表示，是通过一个W矩阵通过index索引得到的每个词的向量表示，通过concat/average所有词的向量表示作为feature去预测另外一个词。在CBOW中，通过前后词预测中间词，模型最终优化的是最大化给定前后词的条件下当前词出现的概率，即：<center>$\frac{1}{T} \sum_{t=k}^{T-k} \log p\left(w_{t} | w_{t-k}, \ldots, w_{t+k}\right)$</center></p>
<p>最终模型通过softmax得到每个词出现的概率：<center>$p\left(w_{t} | w_{t-k}, \ldots, w_{t+k}\right)=\frac{e^{y_{w_{t}}}}{\sum_{i} e^{y_{i}}}$</center></p>
<p>上式中的$\boldsymbol{y}_{i}$是未归一化的每个词出现的概率：<center>$y=b+U h\left(w_{t-k}, \dots, w_{t+k} ; W\right)\qquad ...(1)$</center><br>原始论文中还提到使用层次softmax代替softmax来提升训练速度。详细细节见<a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">原文</a>.</p>
<h3 id="Paragraph-Vector：-A-distributed-memory-model"><a href="#Paragraph-Vector：-A-distributed-memory-model" class="headerlink" title="Paragraph Vector： A distributed memory model"></a>Paragraph Vector： A distributed memory model</h3><p>受word2vec的启发，Paragraph Vector也是通过给出上下文预测下一个word来进行学习的，对应的框架如下：<br><img src="/2019/08/13/doc2vec/2.jpg" alt="2"><br>每个段落/句子通过矩阵D映射到向量空间中，用D的一列代替，同样，每个单词也被映射到向量空间，用矩阵W的一列表示，然后通过段落/句子向量和词向量级连或求平均得到特征预测下一个单词。与word2vec唯一不同的是在计算$y_{i}$时的h是通过W和D average/concat 得到的。</p>
<p>对于D我们可以理解为其他的word，它相当于是上下文的记忆单元活着这个段落的主题，因此我们叫这种训练方法为Distributed Memory Model of Paragraph Vector（PV-DM）。在训练时，通常采用固定长度的滑动窗口得到训练集，段落/句子向量在上下文中是共享的。</p>
<p>总结doc2vec的过程主要是两步：</p>
<ul>
<li>训练阶段，在已知数据集上训练得到模型参数D，W，U，b</li>
<li>预测阶段，得到未知段落的向量D即在固定W，U，b的情况下利用上述方法进行梯度下降，得到新的D（D中会加入表征新段落的column）</li>
</ul>
<p>优点：</p>
<ul>
<li>使用无监督学习，不需要大量有标记数据</li>
<li>能够解决bag-of-words模型的缺点：<ul>
<li>能够学到词之间的语义信息</li>
<li>考虑到了词之间的顺序</li>
</ul>
</li>
</ul>
<h3 id="Paragraph-Vector-without-worf-ordering：-Distributed-bag-of-words"><a href="#Paragraph-Vector-without-worf-ordering：-Distributed-bag-of-words" class="headerlink" title="Paragraph Vector without worf ordering： Distributed bag of words"></a>Paragraph Vector without worf ordering： Distributed bag of words</h3><p>上面提到的训练方法是要综合paragraph vector和word vector去预测下一个词，另一种训练方法可以忽略词的上下文来预测随机从段落/句子采样得到的一个词，具体来说就是每次迭代训练时，采样一个窗口的文本，然后从窗口文本中随机选一个词做预测。我们称这种方法为Distributed Bag of Words version of Paragraph Vector（PV-DBOW）。模型架构如下：<br><img src="/2019/08/13/doc2vec/3.jpg" alt="3"></p>
<hr>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献:"></a>参考文献:</h1><ol>
<li><a href="https://cs.stanford.edu/~quocle/paragraph_vector.pdf" target="_blank" rel="noopener">Distributed Representations of Sentences and Documents</a></li>
<li><a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/08/Exercise-Enhanced-Sequential-Modeling-for-Student-Performance-Prediction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zoe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据挖掘日常笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/08/Exercise-Enhanced-Sequential-Modeling-for-Student-Performance-Prediction/" itemprop="url">Exercise-Enhanced-Sequential-Modeling-for-Student-Performance-Prediction</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-08T15:32:18+08:00">
                2019-08-08
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-08-13T19:15:28+08:00">
                2019-08-13
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deeplearning/" itemprop="url" rel="index">
                    <span itemprop="name">Deeplearning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deeplearning/LSTM/" itemprop="url" rel="index">
                    <span itemprop="name">LSTM</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deeplearning/LSTM/Embedding/" itemprop="url" rel="index">
                    <span itemprop="name">Embedding</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  1.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="EKT-Exercise-aware-Knowledge-Tracing-for-Student-Performance-Prediction"><a href="#EKT-Exercise-aware-Knowledge-Tracing-for-Student-Performance-Prediction" class="headerlink" title="EKT: Exercise-aware Knowledge Tracing for Student Performance Prediction"></a>EKT: Exercise-aware Knowledge Tracing for Student Performance Prediction</h2><p>这篇[文章][10]很早就看到过，但是到2019年6月份才发表出来，本文章认为目前的知识追踪的model都只用了学生的做题信息，而其他的如知识概念或习题内容相关的知识并没有在model中引入，而引入这些信息是能够为模型的预测精度带来增益的，因此作者提出Exercise-Enhanced Recurrent Neural Network(EERNN)，在这个模型中，不仅使用了学生的做题记录，还引入了习题的文本信息。在EERNN中，作者使用RNN的隐变量来表征学生的学习轨迹，使用BiLSTM来学习习题的编码信息。在最终predict阶段，作者在EERNN基础上采用了两种策略，一种是EERNNM with Markov property,另一种是EERNNA with attention mechanism。最终为了追踪学生在各知识点上的掌握情况，作者将EERNN引入知识概念的信息引入得到Exercise-Aware Knowledge Tracing（EKT）。</p>
<h3 id="模型："><a href="#模型：" class="headerlink" title="模型："></a>模型：</h3><p>模型主要分两部分来描述，一是做预测的EERNN（EERNNM &amp; EERNNA），另一部分是追踪学生知识掌握情况的EKT。</p>
<h4 id="EERNN"><a href="#EERNN" class="headerlink" title="EERNN"></a>EERNN</h4><p>EERNN的提出主要用于做学生performance的预测，基于不同的策略又分为EERNNM和EERNNA。网络结果如下图所示：</p>
<p><img src="/2019/08/08/Exercise-Enhanced-Sequential-Modeling-for-Student-Performance-Prediction/EERNN.jpg" alt="EERNN"></p>
<p>从上图可以看出：EERNNM和EERNNA的区别主要在prediction阶段，图中橘色框表示的是题目的embeddig，蓝色框表示的是学生的embedding。</p>
<h5 id="Exercise-embedding"><a href="#Exercise-embedding" class="headerlink" title="Exercise embedding:"></a>Exercise embedding:</h5><p>Exercise embedding的获取是通过双向LSTM得到的，结构如下：<br><img src="/2019/08/08/Exercise-Enhanced-Sequential-Modeling-for-Student-Performance-Prediction/EERNN-1.jpg" alt="EERNN"></p>
<p>通过上述可以得到每个word的embedding $v_{m}=$ concatenate $\left(\vec{v}_{m}, \overleftarrow v_{m}\right)$，最终Exercise的embedding是通过max-pooling每个word的embedding得到，即$x_{i}=\max \left(v_{1}, v_{2}, \ldots, v_{M}\right) x_{i} \in \mathbb{R}^{2 d_{v}}$。</p>
<h5 id="Student-Embedding："><a href="#Student-Embedding：" class="headerlink" title="Student Embedding："></a>Student Embedding：</h5><p>表征学生的向量应该跟题目和学生的回答有关，因此作者在上面获得$x_{i}$的基础上加入了表示学生作答情况的信息，通过RNN/LSTM得到student embedding，具体实现是首先将$r_{t}$表示成一个$2 d_{v}$维的$\mathbf{0}=(0,0, \ldots, 0)$，最终输入$\widetilde{x}_{t} \in \mathbb{R}^{4 d_{v}}$表示为：<center>$\widetilde{x}_{t}=\left\{\begin{array}{ll}{\left[x_{t} \oplus \mathbf{0}\right]} & {\text { if } r_{t}=1} \\ {\left[\mathbf{0} \oplus x_{t}\right]} & {\text { if } \quad r_{t}=0}\end{array}\right.$</center></p>
<h5 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h5><ul>
<li><p>EERNNM:</p>
<p>基于markov性，下一时刻状态的条件概率分布只与当前状态有关，因此对$\widetilde{r}_{T+1}$的预测只与$h_{T}$和$x_{T+1}$有关，因此计算公式如下：<center>$\begin{aligned} y_{T+1} &=\operatorname{Re} L U\left(\mathbf{W}_{1} \cdot\left[h_{T} \oplus x_{T+1}\right]+\mathbf{b}_{1}\right) \\ \widetilde{r}_{T+1} &=\sigma\left(\mathbf{W}_{2} \cdot y_{T+1}+\mathbf{b}_{2}\right) \end{aligned}$   ... (1)</center></p>
</li>
<li><p>EERNNA<br>如果序列很长的话，LSTM捕捉信息的能力会降低，因此为了改善上述问题，引入常用的Attention机制。<br>经过attention后的表征当前状态的隐变量变为：<center>$h_{a t t}=\sum_{j=1}^{T} \alpha_{j} h_{j} \\ \alpha_{j}=\cos \left(x_{T+1}, x_{j}\right)$</center><br>将(1)式中的$h_{a t t}$替换$h_{T}$即可得到预测结果。</p>
</li>
</ul>
<h4 id="EKT-Exercise-aware-Knowledge-Tracing"><a href="#EKT-Exercise-aware-Knowledge-Tracing" class="headerlink" title="EKT: Exercise-aware Knowledge Tracing"></a>EKT: Exercise-aware Knowledge Tracing</h4><p>EKT本质做的是将原始EERNN学习到的学生状态从$h_{t} \in \mathbb{R}^{d_{h}}$变换成$\dot{H}_{t} \in \mathbb{R}^{\dot{d}_{h} \times K}$，也就是说用一个向量来表征学生对某个知识的掌握情况。模型结构如下图所示：<br><img src="/2019/08/08/Exercise-Enhanced-Sequential-Modeling-for-Student-Performance-Prediction/EKT.jpg" alt="EKT"><br>与EERNN相比，除了使用到Exercise Embedding还用到了Knowledge Embedding（对应图中绿色的部分）。</p>
<h5 id="Knowledge-Embedding："><a href="#Knowledge-Embedding：" class="headerlink" title="Knowledge Embedding："></a>Knowledge Embedding：</h5><p>由于知识之间是相关的而非独立的，因此作者引入了memory module来计算当前的知识点与其他知识点的相关性，并最终影响到学生知识状态的隐变量，其中知识间的相关性是通过$\beta_{t}^{i}$实现的。如图中标注，k（K维，K表示所有知识点）表示当前时刻题目对应的知识点的one-hot编码，v（$d_{k}$维）则是将k进行地位压缩后的编码向量$v_{t}=\mathbf{W}_{\mathbf{k}}^{\mathrm{T}} k_{t}$，通过memory module（本质上是一个$d_{k} \times  K$的矩阵），最终$\beta_{t}^{i}$计算公式如下：<center>$\beta_{t}^{i}=\operatorname{Softmax}\left(v_{t}^{\mathrm{T}} \mathbf{M}_{i}\right)=\frac{\exp \left(v_{t}^{\mathrm{T}} \mathbf{M}_{i}\right)}{\sum_{i=1}^{K}\left(\exp \left(v_{t}^{\mathrm{T}} \mathbf{M}_{i}\right)\right)}$</center><br>最终隐状态表示为：<br>$H_{t}^{i}=L S T M\left(\widetilde{x}_{t}^{i}, H_{t-1}^{i} ; \theta_{H^{i}}\right)$，<br>其中$\widetilde{x}_{t}^{i}=\beta_{t}^{i} \hat{x}_{t}$。</p>
<h3 id="结果："><a href="#结果：" class="headerlink" title="结果："></a>结果：</h3><p><img src="/2019/08/08/Exercise-Enhanced-Sequential-Modeling-for-Student-Performance-Prediction/EKT-2.jpg" alt="EKT"></p>
<h3 id="思考："><a href="#思考：" class="headerlink" title="思考："></a>思考：</h3><ul>
<li>EERNN模型为什么只引入题目信息和学生做题记录，为什么不引入知识结构信息？</li>
<li>EKT和EERNN本质是可以做相同的事情，并且结果表明EKT也由于EERNN相关模型。</li>
<li>对应Exercise Embedding为什么采用预训练而不端到端统一到一个model中？</li>
</ul>
<hr>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献:"></a>参考文献:</h2><ol>
<li><a href="https://arxiv.org/pdf/1906.05658.pdf" target="_blank" rel="noopener">EKT: Exercise-aware Knowledge Tracing for Student Performance Prediction</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/08/阿里云 cuda9.1+cudnn 7.1+pytorch 环境搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zoe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据挖掘日常笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/08/阿里云 cuda9.1+cudnn 7.1+pytorch 环境搭建/" itemprop="url">阿里云 cuda9.1+cudnn 7.1+pytorch 环境搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-08T15:32:00+08:00">
                2019-08-08
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-08-08T15:28:33+08:00">
                2019-08-08
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/环境搭建/" itemprop="url" rel="index">
                    <span itemprop="name">环境搭建</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  269
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1-阿里云ECS-默认安装cuda-9-1版本"><a href="#1-阿里云ECS-默认安装cuda-9-1版本" class="headerlink" title="1.阿里云ECS 默认安装cuda 9.1版本"></a>1.阿里云ECS 默认安装cuda 9.1版本</h3><ul>
<li>确定cuda版本： <ul>
<li>首先使用nvidia -smi 查看显卡驱动运行状态</li>
<li>使用nvcc -V查看cuda-toolkit安装是否成功<ul>
<li>若显示nvcc命令不存在：<ul>
<li>使用whereis cuda 查看cuda路径</li>
<li>在～/.bashrc 中加入：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/usr/local/cuda/bin:$PATH </span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64/</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>source ～/.bashrc 命令使环境变量生效    </p>
<h3 id="2-安装Anaconda："><a href="#2-安装Anaconda：" class="headerlink" title="2.  安装Anaconda："></a>2.  安装Anaconda：</h3><p> <a href="https://repo.anaconda.com/archive/" target="_blank" rel="noopener">https://repo.anaconda.com/archive/</a>   版本 Anaconda3-5.1.0-Linux-x86_64.sh</p>
<h3 id="3-安装cudnn："><a href="#3-安装cudnn：" class="headerlink" title="3. 安装cudnn："></a>3. 安装cudnn：</h3><p>从官网下载 <a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener">https://developer.nvidia.com/cudnn</a><br>解压tar -xzvf cudnn-9.1-linux-x64-v7.1.tgz<br>copy到对应cuda文件夹下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo cp cuda/include/cudnn.h /usr/local/cuda/include</span><br><span class="line">sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64</span><br><span class="line">sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure></p>
<p>查看cudnn版本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A5</span><br></pre></td></tr></table></figure></p>
<h3 id="4-安装pytorch"><a href="#4-安装pytorch" class="headerlink" title="4. 安装pytorch"></a>4. 安装pytorch</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision cuda91 -c pytorch</span><br></pre></td></tr></table></figure>
<p>⚠️： 若不成功，可以查看pytorch 版本，可以更改pytorch版本：(实测可用)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install torch==0.4.1</span><br><span class="line">pip install torchvision==0.2.2</span><br></pre></td></tr></table></figure></p>
<h3 id="5-检查安装是否成功："><a href="#5-检查安装是否成功：" class="headerlink" title="5. 检查安装是否成功："></a>5. 检查安装是否成功：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line">import torch</span><br><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure>
<p>【参考文章】：</p>
<ol>
<li><a href="https://blog.csdn.net/qq_29762941/article/details/80630585" target="_blank" rel="noopener">https://blog.csdn.net/qq_29762941/article/details/80630585</a></li>
<li><a href="https://blog.csdn.net/qq_29762941/article/details/80630585" target="_blank" rel="noopener">https://blog.csdn.net/qq_29762941/article/details/80630585</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpeg" alt="Zoe">
            
              <p class="site-author-name" itemprop="name">Zoe</p>
              <p class="site-description motion-element" itemprop="description">Every failure is leading towards success.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zoe</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">19.6k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
